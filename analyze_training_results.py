import csv
import yaml
import os
from pathlib import Path
import json
from collections import defaultdict, Counter

def read_csv_file(filepath):
    """è¯»å–CSVæ–‡ä»¶"""
    data = []
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                data.append(row)
    except Exception as e:
        print(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥ {filepath}: {e}")
        return []
    return data

def analyze_training_results():
    """åˆ†ææ‰€æœ‰è®­ç»ƒç»“æœå¹¶ç”ŸæˆæŠ¥å‘Š"""
    
    runs_dir = Path("runs/detect")
    training_results = []
    
    print("å¼€å§‹åˆ†æè®­ç»ƒç»“æœ...")
    
    # éå†æ‰€æœ‰è®­ç»ƒç›®å½•
    for train_dir in runs_dir.iterdir():
        if train_dir.is_dir() and train_dir.name.startswith('train'):
            try:
                # æå–è®­ç»ƒç¼–å·
                train_name = train_dir.name
                if train_name == 'train':
                    train_num = 0
                else:
                    # å¤„ç†åƒ 'train21' è¿™æ ·çš„åç§°
                    num_part = train_name.replace('train', '')
                    if num_part:
                        train_num = int(num_part)
                    else:
                        continue
                        
                print(f"å¤„ç†è®­ç»ƒç›®å½•: {train_name} (ç¼–å·: {train_num})")
                
                # æ£€æŸ¥å¿…è¦æ–‡ä»¶
                results_file = train_dir / "results.csv"
                args_file = train_dir / "args.yaml"
                report_file = train_dir / "training_report.txt"
                
                if not (results_file.exists() and args_file.exists()):
                    print(f"  è·³è¿‡: ç¼ºå°‘å¿…è¦æ–‡ä»¶")
                    continue
                
                # è¯»å–è®­ç»ƒç»“æœ
                results_data = read_csv_file(results_file)
                if not results_data:
                    print(f"  è·³è¿‡: æ— æ³•è¯»å–ç»“æœæ–‡ä»¶")
                    continue
                
                # è¯»å–é…ç½®å‚æ•°
                try:
                    with open(args_file, 'r', encoding='utf-8') as f:
                        args = yaml.safe_load(f)
                except Exception as e:
                    print(f"  è·³è¿‡: æ— æ³•è¯»å–é…ç½®æ–‡ä»¶ - {e}")
                    continue
                
                # æå–å…³é”®æŒ‡æ ‡
                if len(results_data) == 0:
                    continue
                
                # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                map50_values = []
                map5095_values = []
                precision_values = []
                recall_values = []
                
                for row in results_data:
                    try:
                        map50_values.append(float(row.get('metrics/mAP50(B)', 0)))
                        map5095_values.append(float(row.get('metrics/mAP50-95(B)', 0)))
                        precision_values.append(float(row.get('metrics/precision(B)', 0)))
                        recall_values.append(float(row.get('metrics/recall(B)', 0)))
                    except (ValueError, KeyError):
                        continue
                
                if not map50_values:
                    print(f"  è·³è¿‡: æ— æ³•æå–æ€§èƒ½æŒ‡æ ‡")
                    continue
                
                # æ‰¾åˆ°æœ€ä½³æ€§èƒ½
                best_map50_idx = max(range(len(map50_values)), key=lambda i: map50_values[i])
                final_idx = len(results_data) - 1
                
                # è¯»å–è®­ç»ƒæŠ¥å‘Šï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                report_data = {}
                if report_file.exists():
                    try:
                        with open(report_file, 'r', encoding='utf-8') as f:
                            for line in f:
                                line = line.strip()
                                if 'æœ€ä½³mAP@0.5:' in line:
                                    try:
                                        report_data['best_map50_report'] = float(line.split(':')[1].strip())
                                    except:
                                        pass
                                elif 'æœ€ç»ˆmAP@0.5:0.95:' in line:
                                    try:
                                        report_data['final_map5095_report'] = float(line.split(':')[1].strip())
                                    except:
                                        pass
                    except:
                        pass
                
                # æå–è®­ç»ƒä¿¡æ¯
                training_info = {
                    'train_num': train_num,
                    'model': args.get('model', 'unknown'),
                    'epochs': args.get('epochs', 0),
                    'batch_size': args.get('batch', 0),
                    'optimizer': args.get('optimizer', 'unknown'),
                    'lr0': args.get('lr0', 0.001),
                    'lrf': args.get('lrf', 0.01),
                    
                    # æœ€ä½³æ€§èƒ½æŒ‡æ ‡
                    'best_map50': map50_values[best_map50_idx],
                    'best_map5095': map5095_values[best_map50_idx] if map5095_values else 0,
                    'best_epoch': best_map50_idx + 1,
                    'best_precision': precision_values[best_map50_idx] if precision_values else 0,
                    'best_recall': recall_values[best_map50_idx] if recall_values else 0,
                    
                    # æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡
                    'final_map50': map50_values[-1],
                    'final_map5095': map5095_values[-1] if map5095_values else 0,
                    'final_precision': precision_values[-1] if precision_values else 0,
                    'final_recall': recall_values[-1] if recall_values else 0,
                    
                    # æŸå¤±å‡½æ•°
                    'final_box_loss': float(results_data[-1].get('train/box_loss', 0)),
                    'final_cls_loss': float(results_data[-1].get('train/cls_loss', 0)),
                    'final_dfl_loss': float(results_data[-1].get('train/dfl_loss', 0)),
                    
                    'final_val_box_loss': float(results_data[-1].get('val/box_loss', 0)),
                    'final_val_cls_loss': float(results_data[-1].get('val/cls_loss', 0)),
                    'final_val_dfl_loss': float(results_data[-1].get('val/dfl_loss', 0)),
                    
                    # è®­ç»ƒæ—¶é—´
                    'total_time': float(results_data[-1].get('time', 0)),
                    
                    # æ•°æ®å¢å¼ºå‚æ•°
                    'mosaic': args.get('mosaic', 0),
                    'mixup': args.get('mixup', 0),
                    'copy_paste': args.get('copy_paste', 0),
                    'degrees': args.get('degrees', 0),
                    'translate': args.get('translate', 0),
                    'scale': args.get('scale', 0),
                    
                    # æŠ¥å‘Šæ•°æ®
                    **report_data
                }
                
                training_results.append(training_info)
                print(f"  âœ“ æˆåŠŸæå– {len(results_data)} ä¸ªè½®æ¬¡çš„æ•°æ®")
                
            except Exception as e:
                print(f"  âœ— å¤„ç†å¤±è´¥: {e}")
                continue
    
    if not training_results:
        print("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è®­ç»ƒç»“æœ")
        return None
    
    # æŒ‰è®­ç»ƒç¼–å·æ’åº
    training_results.sort(key=lambda x: x['train_num'])
    
    print(f"\næˆåŠŸåˆ†æ {len(training_results)} ä¸ªè®­ç»ƒç»“æœ")
    return training_results

def generate_analysis_report(training_results):
    """ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š"""
    
    if not training_results:
        print("æ²¡æœ‰è®­ç»ƒç»“æœå¯ä¾›åˆ†æ")
        return
    
    print("\n" + "=" * 80)
    print("é“è·¯ç—…å®³æ£€æµ‹ç³»ç»Ÿ - è®­ç»ƒç»“æœåˆ†ææŠ¥å‘Š")
    print("=" * 80)
    print()
    
    # 1. æ€»ä½“æ¦‚è§ˆ
    print("ğŸ“Š æ€»ä½“æ¦‚è§ˆ")
    print("-" * 40)
    print(f"æ€»è®­ç»ƒæ¬¡æ•°: {len(training_results)}")
    
    best_map50 = max(training_results, key=lambda x: x['best_map50'])
    best_map5095 = max(training_results, key=lambda x: x['best_map5095'])
    
    print(f"æœ€ä½³mAP@0.5: {best_map50['best_map50']:.4f} (è®­ç»ƒ #{best_map50['train_num']})")
    print(f"æœ€ä½³mAP@0.5:0.95: {best_map5095['best_map5095']:.4f} (è®­ç»ƒ #{best_map5095['train_num']})")
    
    avg_time = sum(r['total_time'] for r in training_results) / len(training_results)
    print(f"å¹³å‡è®­ç»ƒæ—¶é—´: {avg_time/3600:.1f} å°æ—¶")
    print()
    
    # 2. æœ€ä½³æ¨¡å‹åˆ†æ
    print("ğŸ† æœ€ä½³æ¨¡å‹åˆ†æ")
    print("-" * 40)
    
    print(f"æœ€ä½³æ¨¡å‹: è®­ç»ƒ #{best_map50['train_num']}")
    print(f"æ¨¡å‹ç±»å‹: {best_map50['model']}")
    print(f"æœ€ä½³mAP@0.5: {best_map50['best_map50']:.4f}")
    print(f"æœ€ä½³mAP@0.5:0.95: {best_map50['best_map5095']:.4f}")
    print(f"æœ€ä½³ç²¾åº¦: {best_map50['best_precision']:.4f}")
    print(f"æœ€ä½³å¬å›ç‡: {best_map50['best_recall']:.4f}")
    print(f"è¾¾åˆ°æœ€ä½³æ€§èƒ½çš„è½®æ¬¡: {best_map50['best_epoch']}")
    print()
    
    # 3. æ¨¡å‹å¯¹æ¯”åˆ†æ
    print("ğŸ” æ¨¡å‹å¯¹æ¯”åˆ†æ")
    print("-" * 40)
    
    # æŒ‰æ¨¡å‹ç±»å‹åˆ†ç»„
    model_groups = defaultdict(list)
    for result in training_results:
        model_type = result['model']
        model_groups[model_type].append(result)
    
    for model_type, group in model_groups.items():
        map50_values = [r['best_map50'] for r in group]
        map5095_values = [r['best_map5095'] for r in group]
        
        print(f"\næ¨¡å‹ç±»å‹: {model_type}")
        print(f"  è®­ç»ƒæ¬¡æ•°: {len(group)}")
        print(f"  å¹³å‡æœ€ä½³mAP@0.5: {sum(map50_values)/len(map50_values):.4f}")
        print(f"  æœ€é«˜mAP@0.5: {max(map50_values):.4f}")
        print(f"  å¹³å‡æœ€ä½³mAP@0.5:0.95: {sum(map5095_values)/len(map5095_values):.4f}")
        print(f"  æœ€é«˜mAP@0.5:0.95: {max(map5095_values):.4f}")
    
    print()
    
    # 4. è®­ç»ƒé…ç½®åˆ†æ
    print("âš™ï¸ è®­ç»ƒé…ç½®åˆ†æ")
    print("-" * 40)
    
    # å­¦ä¹ ç‡åˆ†æ
    lr_groups = defaultdict(list)
    for result in training_results:
        lr = result['lr0']
        if lr < 0.001:
            lr_groups['ä½å­¦ä¹ ç‡(<0.001)'].append(result)
        elif lr < 0.01:
            lr_groups['ä¸­å­¦ä¹ ç‡(0.001-0.01)'].append(result)
        else:
            lr_groups['é«˜å­¦ä¹ ç‡(>0.01)'].append(result)
    
    print("å­¦ä¹ ç‡å½±å“:")
    for lr_range, group in lr_groups.items():
        avg_map50 = sum(r['best_map50'] for r in group) / len(group)
        print(f"  {lr_range}: å¹³å‡mAP@0.5 = {avg_map50:.4f} ({len(group)}æ¬¡è®­ç»ƒ)")
    
    # è®­ç»ƒè½®æ¬¡åˆ†æ
    epoch_groups = defaultdict(list)
    for result in training_results:
        epochs = result['epochs']
        if epochs <= 50:
            epoch_groups['çŸ­è®­ç»ƒ(â‰¤50è½®)'].append(result)
        elif epochs <= 100:
            epoch_groups['ä¸­è®­ç»ƒ(51-100è½®)'].append(result)
        else:
            epoch_groups['é•¿è®­ç»ƒ(>100è½®)'].append(result)
    
    print("\nè®­ç»ƒè½®æ¬¡å½±å“:")
    for epoch_range, group in epoch_groups.items():
        avg_map50 = sum(r['best_map50'] for r in group) / len(group)
        print(f"  {epoch_range}: å¹³å‡mAP@0.5 = {avg_map50:.4f} ({len(group)}æ¬¡è®­ç»ƒ)")
    
    print()
    
    # 5. æŸå¤±å‡½æ•°åˆ†æ
    print("ğŸ“‰ æŸå¤±å‡½æ•°åˆ†æ")
    print("-" * 40)
    
    avg_losses = {
        'Box Loss': sum(r['final_box_loss'] for r in training_results) / len(training_results),
        'Classification Loss': sum(r['final_cls_loss'] for r in training_results) / len(training_results),
        'DFL Loss': sum(r['final_dfl_loss'] for r in training_results) / len(training_results),
        'Val Box Loss': sum(r['final_val_box_loss'] for r in training_results) / len(training_results),
        'Val Classification Loss': sum(r['final_val_cls_loss'] for r in training_results) / len(training_results),
        'Val DFL Loss': sum(r['final_val_dfl_loss'] for r in training_results) / len(training_results)
    }
    
    for loss_name, avg_loss in avg_losses.items():
        print(f"{loss_name}: {avg_loss:.4f}")
    
    print()
    
    # 6. æ•°æ®å¢å¼ºæ•ˆæœåˆ†æ
    print("ğŸ¨ æ•°æ®å¢å¼ºæ•ˆæœåˆ†æ")
    print("-" * 40)
    
    # Mosaicæ•ˆæœ
    high_mosaic = [r for r in training_results if r['mosaic'] > 0.5]
    low_mosaic = [r for r in training_results if r['mosaic'] <= 0.5]
    
    if high_mosaic and low_mosaic:
        high_mosaic_avg = sum(r['best_map50'] for r in high_mosaic) / len(high_mosaic)
        low_mosaic_avg = sum(r['best_map50'] for r in low_mosaic) / len(low_mosaic)
        print(f"Mosaicå½±å“: é«˜Mosaic({high_mosaic_avg:.4f}) vs ä½Mosaic({low_mosaic_avg:.4f})")
    
    # Mixupæ•ˆæœ
    high_mixup = [r for r in training_results if r['mixup'] > 0.3]
    low_mixup = [r for r in training_results if r['mixup'] <= 0.3]
    
    if high_mixup and low_mixup:
        high_mixup_avg = sum(r['best_map50'] for r in high_mixup) / len(high_mixup)
        low_mixup_avg = sum(r['best_map50'] for r in low_mixup) / len(low_mixup)
        print(f"Mixupå½±å“: é«˜Mixup({high_mixup_avg:.4f}) vs ä½Mixup({low_mixup_avg:.4f})")
    
    print()
    
    # 7. æ¨èé…ç½®
    print("ğŸ’¡ æ¨èé…ç½®")
    print("-" * 40)
    
    best_config = best_map50
    
    print("åŸºäºæœ€ä½³æ€§èƒ½æ¨¡å‹çš„æ¨èé…ç½®:")
    print(f"  æ¨¡å‹: {best_config['model']}")
    print(f"  å­¦ä¹ ç‡: {best_config['lr0']}")
    print(f"  å­¦ä¹ ç‡è¡°å‡: {best_config['lrf']}")
    print(f"  ä¼˜åŒ–å™¨: {best_config['optimizer']}")
    print(f"  Mosaic: {best_config['mosaic']}")
    print(f"  Mixup: {best_config['mixup']}")
    print(f"  Copy Paste: {best_config['copy_paste']}")
    print(f"  æ•°æ®å¢å¼º: {best_config['degrees']}Â°æ—‹è½¬, {best_config['translate']}å¹³ç§», {best_config['scale']}ç¼©æ”¾")
    
    print()
    
    # 8. è®­ç»ƒè¶‹åŠ¿åˆ†æ
    print("ğŸ“ˆ è®­ç»ƒè¶‹åŠ¿åˆ†æ")
    print("-" * 40)
    
    # è®¡ç®—è®­ç»ƒç¼–å·ä¸æ€§èƒ½çš„ç›¸å…³æ€§
    train_nums = [r['train_num'] for r in training_results]
    map50_values = [r['best_map50'] for r in training_results]
    map5095_values = [r['best_map5095'] for r in training_results]
    
    # ç®€å•çš„ç›¸å…³æ€§è®¡ç®—
    if len(train_nums) > 2:
        correlation_map50 = calculate_correlation(train_nums, map50_values)
        correlation_map5095 = calculate_correlation(train_nums, map5095_values)
        
        print(f"è®­ç»ƒè½®æ¬¡ä¸mAP@0.5ç›¸å…³æ€§: {correlation_map50:.3f}")
        print(f"è®­ç»ƒè½®æ¬¡ä¸mAP@0.5:0.95ç›¸å…³æ€§: {correlation_map5095:.3f}")
        
        if correlation_map50 > 0.3:
            print("âœ… æ¨¡å‹æ€§èƒ½éšè®­ç»ƒè½®æ¬¡æå‡æ˜æ˜¾")
        elif correlation_map50 > 0.1:
            print("ğŸ“Š æ¨¡å‹æ€§èƒ½ç•¥æœ‰æå‡")
        else:
            print("âš ï¸ æ¨¡å‹æ€§èƒ½æå‡ä¸æ˜æ˜¾")
    
    print()
    print("=" * 80)
    
    # ä¿å­˜è¯¦ç»†ç»“æœåˆ°JSONæ–‡ä»¶
    save_results_to_json(training_results, 'training_results_analysis.json')
    
    return training_results

def calculate_correlation(x, y):
    """è®¡ç®—ä¸¤ä¸ªåˆ—è¡¨çš„çš®å°”é€Šç›¸å…³ç³»æ•°"""
    if len(x) != len(y) or len(x) < 2:
        return 0
    
    n = len(x)
    sum_x = sum(x)
    sum_y = sum(y)
    sum_xy = sum(x[i] * y[i] for i in range(n))
    sum_x2 = sum(x[i] ** 2 for i in range(n))
    sum_y2 = sum(y[i] ** 2 for i in range(n))
    
    numerator = n * sum_xy - sum_x * sum_y
    denominator = ((n * sum_x2 - sum_x ** 2) * (n * sum_y2 - sum_y ** 2)) ** 0.5
    
    if denominator == 0:
        return 0
    
    return numerator / denominator

def save_results_to_json(results, filename):
    """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶"""
    try:
        # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
        json_results = []
        for result in results:
            json_result = {}
            for key, value in result.items():
                if isinstance(value, (int, float, str, bool)):
                    json_result[key] = value
                else:
                    json_result[key] = float(value) if isinstance(value, (int, float)) else str(value)
            json_results.append(json_result)
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(json_results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“ è¯¦ç»†åˆ†æç»“æœå·²ä¿å­˜åˆ° {filename}")
        
    except Exception as e:
        print(f"ä¿å­˜JSONæ–‡ä»¶å¤±è´¥: {e}")

if __name__ == "__main__":
    print("å¼€å§‹åˆ†æè®­ç»ƒç»“æœ...")
    
    # è¿è¡Œåˆ†æ
    training_results = analyze_training_results()
    
    if training_results:
        print("\nç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        generate_analysis_report(training_results)
        print("\nâœ… åˆ†æå®Œæˆï¼")
    else:
        print("\nâŒ åˆ†æå¤±è´¥ï¼Œæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è®­ç»ƒç»“æœ")