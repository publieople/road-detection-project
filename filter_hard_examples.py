#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éªŒè¯é›†å¤±è´¥æ ·æœ¬å¤„ç†è„šæœ¬ - æ ¹æ®æ¨¡å‹æ¨ç†å¤±è´¥ç»“æœå¤„ç†éªŒè¯å¤±è´¥çš„æ ·æœ¬
Failed Validation Filter - Remove samples where model inference fails
"""

import argparse
import sys
import json
import random
import shutil
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from collections import defaultdict

import numpy as np
import torch
import yaml
from PIL import Image

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.append(str(Path(__file__).parent))

def load_dataset_config(yaml_path: str) -> Dict:
    """åŠ è½½YOLOæ ¼å¼æ•°æ®é›†é…ç½®"""
    with open(yaml_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def load_yolo_labels(label_path: str) -> List[np.ndarray]:
    """
    åŠ è½½YOLOæ ¼å¼æ ‡ç­¾ (cx, cy, w, h, class_id)
    è¿”å›: [(class_id, cx, cy, w, h), ...]
    """
    boxes = []
    if not Path(label_path).exists():
        return boxes

    try:
        with open(label_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                parts = list(map(float, line.split()))
                if len(parts) >= 5:
                    boxes.append(parts[:5])  # class_id, cx, cy, w, h
    except Exception as e:
        print(f"âš ï¸  è¯»å–æ ‡ç­¾å¤±è´¥ {label_path}: {e}")

    return boxes

def has_class_in_whitelist(label_path: str, class_whitelist: Optional[List[int]] = None) -> bool:
    """
    æ£€æŸ¥æ ·æœ¬æ˜¯å¦åŒ…å«ç™½åå•ä¸­çš„ç±»åˆ«

    Args:
        label_path: æ ‡ç­¾æ–‡ä»¶è·¯å¾„
        class_whitelist: ç±»åˆ«ç™½åå• [0, 1, 2, ...] æˆ– None è¡¨ç¤ºä¸åšè¿‡æ»¤

    Returns:
        å¦‚æœç™½åå•ä¸ºç©º/Noneè¿”å›Trueï¼ˆä¸è¿‡æ»¤ï¼‰
        å¦‚æœæ ·æœ¬ä¸­æœ‰ç™½åå•å†…çš„ç±»åˆ«è¿”å›True
        å¦åˆ™è¿”å›False
    """
    # å¦‚æœæ²¡æœ‰è®¾ç½®ç™½åå•ï¼Œé»˜è®¤æ¥å—æ‰€æœ‰æ ·æœ¬
    if class_whitelist is None or len(class_whitelist) == 0:
        return True

    # è½¬æ¢ä¸ºé›†åˆä»¥åŠ å¿«æŸ¥æ‰¾
    whitelist_set = set(class_whitelist)

    # åŠ è½½æ ‡ç­¾å¹¶æ£€æŸ¥
    boxes = load_yolo_labels(label_path)
    for box in boxes:
        class_id = int(box[0])
        if class_id in whitelist_set:
            return True

    return False

def normalize_box(box: np.ndarray, img_width: int, img_height: int) -> Tuple[int, int, int, int, int]:
    """
    å°†YOLOæ ¼å¼å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºåƒç´ åæ ‡
    YOLOæ ¼å¼: (cx, cy, w, h) - éƒ½æ˜¯ç›¸å¯¹äºå›¾åƒå°ºå¯¸çš„æ¯”ä¾‹ [0, 1]
    è¾“å‡º: (class_id, x1, y1, x2, y2) - åƒç´ åæ ‡
    """
    class_id, cx, cy, w, h = box

    x1 = int((cx - w/2) * img_width)
    y1 = int((cy - h/2) * img_height)
    x2 = int((cx + w/2) * img_width)
    y2 = int((cy + h/2) * img_height)

    return int(class_id), x1, y1, x2, y2

def calculate_iou(box1: np.ndarray, box2: np.ndarray) -> float:
    """è®¡ç®—ä¸¤ä¸ª(x1,y1,x2,y2)æ ¼å¼çš„æ¡†çš„IoU"""
    x1_1, y1_1, x2_1, y2_1 = box1[:4]
    x1_2, y1_2, x2_2, y2_2 = box2[:4]

    # è®¡ç®—äº¤é›†
    inter_x1 = max(x1_1, x1_2)
    inter_y1 = max(y1_1, y1_2)
    inter_x2 = min(x2_1, x2_2)
    inter_y2 = min(y2_1, y2_2)

    if inter_x2 <= inter_x1 or inter_y2 <= inter_y1:
        return 0.0

    inter_area = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)

    # è®¡ç®—å¹¶é›†
    box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)
    box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)
    union_area = box1_area + box2_area - inter_area

    if union_area <= 0:
        return 0.0

    return inter_area / union_area

def match_predictions_to_labels(preds: List[np.ndarray], labels: List[np.ndarray],
                                iou_threshold: float = 0.5) -> Tuple[List[float], List[int]]:
    """
    åŒ¹é…é¢„æµ‹æ¡†å’Œæ ‡ç­¾æ¡†ï¼Œè®¡ç®—IoU

    Args:
        preds: é¢„æµ‹æ¡†åˆ—è¡¨ [(x1,y1,x2,y2,conf), ...]
        labels: æ ‡ç­¾æ¡†åˆ—è¡¨ [(class_id,x1,y1,x2,y2), ...]
        iou_threshold: IoUé˜ˆå€¼

    Returns:
        (åŒ¹é…IoUåˆ—è¡¨, æœªåŒ¹é…æ ‡ç­¾ç´¢å¼•åˆ—è¡¨)
    """
    matched_ious = []
    unmatched_label_indices = list(range(len(labels)))

    # å¯¹æ¯ä¸ªé¢„æµ‹æ¡†ï¼Œæ‰¾æœ€ä½³åŒ¹é…çš„æ ‡ç­¾æ¡†
    for pred in preds:
        best_iou = 0.0
        best_label_idx = -1

        for label_idx, label in enumerate(labels):
            if label_idx not in unmatched_label_indices:
                continue

            iou = calculate_iou(pred, label)
            if iou > best_iou:
                best_iou = iou
                best_label_idx = label_idx

        if best_label_idx >= 0 and best_iou >= iou_threshold:
            matched_ious.append(best_iou)
            unmatched_label_indices.remove(best_label_idx)

    return matched_ious, unmatched_label_indices

def infer_with_yolo(model, image_path: str, conf_threshold: float = 0.25) -> List[np.ndarray]:
    """
    ä½¿ç”¨YOLOæ¨¡å‹æ¨ç†å›¾ç‰‡

    Args:
        model: YOLOæ¨¡å‹
        image_path: å›¾ç‰‡è·¯å¾„
        conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼

    Returns:
        é¢„æµ‹æ¡†åˆ—è¡¨ [(x1,y1,x2,y2,conf,class_id), ...]
    """
    try:
        results = model(image_path, conf=conf_threshold, verbose=False)

        preds = []
        if results and len(results) > 0:
            boxes = results[0].boxes
            if boxes is not None:
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    conf = box.conf[0].item()
                    class_id = int(box.cls[0].item())
                    preds.append(np.array([x1, y1, x2, y2, conf, class_id]))

        return preds
    except Exception as e:
        print(f"âš ï¸  æ¨ç†å¤±è´¥ {image_path}: {e}")
        return []

def calculate_sample_difficulty(image_path: str, label_path: str, model,
                               iou_threshold: float = 0.5) -> Dict[str, Any]:
    """
    è®¡ç®—æ ·æœ¬çš„éš¾åº¦æŒ‡æ ‡

    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        label_path: æ ‡ç­¾è·¯å¾„
        model: YOLOæ¨¡å‹
        iou_threshold: IoUé˜ˆå€¼

    Returns:
        éš¾åº¦æŒ‡æ ‡å­—å…¸
    """
    try:
        # è·å–å›¾ç‰‡å°ºå¯¸
        img = Image.open(image_path)
        img_width, img_height = img.size

        # åŠ è½½æ ‡ç­¾å’Œæ¨ç†
        gt_boxes_yolo = load_yolo_labels(label_path)
        preds = infer_with_yolo(model, image_path)

        # è½¬æ¢åæ ‡æ ¼å¼
        gt_boxes_pixel = []
        for box in gt_boxes_yolo:
            class_id, x1, y1, x2, y2 = normalize_box(box, img_width, img_height)
            gt_boxes_pixel.append(np.array([x1, y1, x2, y2, float(class_id)]))

        # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œéš¾åº¦è®¾ä¸ºä¸­ç­‰
        if len(gt_boxes_pixel) == 0:
            return {
                'has_objects': False,
                'num_gt': 0,
                'num_pred': len(preds),
                'mean_iou': 0.5,
                'min_iou': 0.5,
                'max_conf': float(max([p[4] for p in preds])) if preds else 0.0,
                'mean_conf': float(np.mean([p[4] for p in preds])) if preds else 0.0,
                'unmatched_count': 0,
                'false_positive_count': len(preds)
            }

        # å¦‚æœæœ‰æ ‡ç­¾ä½†æ— é¢„æµ‹ï¼Œéš¾åº¦å¾ˆé«˜
        if len(preds) == 0:
            return {
                'has_objects': True,
                'num_gt': len(gt_boxes_pixel),
                'num_pred': 0,
                'mean_iou': 0.0,
                'min_iou': 0.0,
                'max_conf': 0.0,
                'mean_conf': 0.0,
                'unmatched_count': len(gt_boxes_pixel),
                'false_positive_count': 0
            }

        # åŒ¹é…é¢„æµ‹å’Œæ ‡ç­¾
        matched_ious, unmatched_indices = match_predictions_to_labels(
            preds, gt_boxes_pixel, iou_threshold
        )

        # è®¡ç®—æŒ‡æ ‡
        mean_iou = float(np.mean(matched_ious)) if matched_ious else 0.0
        min_iou = float(np.min(matched_ious)) if matched_ious else 0.0
        max_conf = float(max([p[4] for p in preds]))
        mean_conf = float(np.mean([p[4] for p in preds]))
        unmatched_count = len(unmatched_indices)
        false_positive_count = len(preds) - len(matched_ious)

        return {
            'has_objects': True,
            'num_gt': len(gt_boxes_pixel),
            'num_pred': len(preds),
            'mean_iou': mean_iou,
            'min_iou': min_iou,
            'max_conf': max_conf,
            'mean_conf': mean_conf,
            'unmatched_count': unmatched_count,
            'false_positive_count': false_positive_count
        }

    except Exception as e:
        print(f"âš ï¸  è®¡ç®—éš¾åº¦å¤±è´¥ {image_path}: {e}")
        return {
            'has_objects': False,
            'num_gt': 0,
            'num_pred': 0,
            'mean_iou': 0.5,
            'min_iou': 0.5,
            'max_conf': 0.0,
            'mean_conf': 0.0,
            'unmatched_count': 0,
            'false_positive_count': 0,
            'error': str(e)
        }

def check_inference_pass(metrics: Dict[str, float],
                        iou_threshold: float = 0.5) -> Tuple[bool, str]:
    """
    åˆ¤æ–­æ ·æœ¬çš„æ¨ç†éªŒè¯æ˜¯å¦é€šè¿‡

    éªŒè¯å¤±è´¥çš„æƒ…å†µï¼š
    1. æœ‰çœŸå®æ ‡ç­¾ä½†æ¨¡å‹æœªæ£€æµ‹åˆ° (num_pred == 0)
    2. æ£€æµ‹åˆ°ä½†IoUè¿‡ä½ (mean_iou < iou_threshold)
    3. æ¼æ£€ç‡è¿‡é«˜ (æœªåŒ¹é…çš„çœŸå®æ¡†è¿‡å¤š)

    Args:
        metrics: éš¾åº¦æŒ‡æ ‡å­—å…¸
        iou_threshold: IoUé€šè¿‡é˜ˆå€¼

    Returns:
        (æ˜¯å¦é€šè¿‡, å¤±è´¥åŸå› )
    """
    if 'error' in metrics:
        return False, "å¤„ç†é”™è¯¯"

    # æƒ…å†µ1: æœ‰æ ‡ç­¾ä½†æ— é¢„æµ‹ = éªŒè¯å¤±è´¥
    if metrics['has_objects'] and metrics['num_pred'] == 0:
        return False, "æ¼æ£€:æ— é¢„æµ‹"

    # æƒ…å†µ2: æ— æ ‡ç­¾ = éªŒè¯é€šè¿‡
    if not metrics['has_objects'] and metrics['num_pred'] == 0:
        return True, "æ­£ç¡®:æ— ç›®æ ‡æ— é¢„æµ‹"

    # æƒ…å†µ3: æœ‰æ ‡ç­¾çš„æƒ…å†µä¸‹ï¼ŒIoUè¿‡ä½ = éªŒè¯å¤±è´¥
    if metrics['has_objects'] and metrics['mean_iou'] < iou_threshold:
        return False, f"IoUè¿‡ä½:{metrics['mean_iou']:.3f}"

    # æƒ…å†µ4: æ¼æ£€ç‡è¿‡é«˜ = éªŒè¯å¤±è´¥
    if metrics['unmatched_count'] > 0:
        miss_rate = metrics['unmatched_count'] / max(metrics['num_gt'], 1)
        if miss_rate > 0.3:  # æ¼æ£€è¶…è¿‡30%
            return False, f"æ¼æ£€ç‡é«˜:{miss_rate:.1%}"

    # æƒ…å†µ5: è¯¯æ£€è¿‡å¤š = éªŒè¯å¤±è´¥
    if metrics['false_positive_count'] > metrics['num_gt']:
        return False, f"è¯¯æ£€è¿‡å¤š:{metrics['false_positive_count']}"

    return True, "é€šè¿‡éªŒè¯"



def scan_training_samples(config: Dict, yaml_dir: Path, model,
                         iou_threshold: float = 0.5) -> Dict[str, Dict[str, Any]]:
    """
    æ‰«æè®­ç»ƒé›†ä¸­æ‰€æœ‰æ ·æœ¬çš„éªŒè¯æƒ…å†µ

    Args:
        config: æ•°æ®é…ç½®å­—å…¸
        yaml_dir: é…ç½®æ–‡ä»¶æ‰€åœ¨ç›®å½•
        model: YOLOæ¨¡å‹
        iou_threshold: IoUé˜ˆå€¼

    Returns:
        {image_path: {'metrics': ..., 'is_pass': ..., 'reason': ...}, ...}
    """
    train_images_rel = config.get('train', 'images/train')
    train_images_path = yaml_dir / train_images_rel

    if not train_images_path.exists():
        print(f"âš ï¸  è®­ç»ƒé›†è·¯å¾„ä¸å­˜åœ¨: {train_images_path}")
        return {}

    # è·å–æ ‡ç­¾è·¯å¾„æ˜ å°„
    def get_label_path(image_path: Path) -> Path:
        rel_path = image_path.relative_to(train_images_path)
        labels_dir = yaml_dir / 'labels' / 'train'
        label_path = labels_dir / rel_path.with_suffix('.txt')
        return label_path

    # åˆ—å‡ºæ‰€æœ‰è®­ç»ƒå›¾ç‰‡
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
    image_files = [f for f in train_images_path.rglob('*')
                   if f.suffix.lower() in image_extensions and f.is_file()]

    print(f"\nğŸ“Š æ‰«æè®­ç»ƒé›†æ ·æœ¬ ({len(image_files)}å¼ å›¾ç‰‡)...")

    train_samples = {}
    passed_count = 0

    for idx, image_path in enumerate(image_files):
        if (idx + 1) % max(1, len(image_files) // 10) == 0:
            print(f"   è¿›åº¦: {idx + 1}/{len(image_files)}")

        label_path = get_label_path(image_path)
        metrics = calculate_sample_difficulty(image_path, str(label_path), model, iou_threshold)
        is_pass, reason = check_inference_pass(metrics, iou_threshold)

        train_samples[str(image_path)] = {
            'metrics': metrics,
            'is_pass': is_pass,
            'reason': reason
        }

        if is_pass:
            passed_count += 1

    print(f"   è®­ç»ƒé›†ä¸­é€šè¿‡éªŒè¯çš„æ ·æœ¬: {passed_count}/{len(image_files)}")

    return train_samples


def filter_failed_validations(data_yaml_path: str, model_path: str,
                              action_prob: float = 1.0,
                              iou_threshold: float = 0.5,
                              action: str = 'move',
                              output_dir: Optional[str] = None,
                              backup: bool = True,
                              enable_replacement: bool = False,
                              include_classes: Optional[List[int]] = None) -> Dict[str, Any]:
    """
    å¤„ç†éªŒè¯é›†ä¸­æ¨ç†éªŒè¯å¤±è´¥çš„æ ·æœ¬

    Args:
        data_yaml_path: æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„
        model_path: YOLOæ¨¡å‹è·¯å¾„
        action_prob: æ“ä½œæ¦‚ç‡ [0, 1]ï¼ŒéªŒè¯å¤±è´¥çš„æ ·æœ¬ä»¥æ­¤æ¦‚ç‡æ‰§è¡Œactionæ“ä½œ
        iou_threshold: IoUé˜ˆå€¼ [0, 1]ï¼Œåˆ¤æ–­éªŒè¯æ˜¯å¦é€šè¿‡çš„æ ‡å‡†
        action: æ“ä½œç±»å‹ï¼Œ'move'ï¼ˆé»˜è®¤ï¼‰å°†å¤±è´¥æ ·æœ¬ç§»åˆ°è®­ç»ƒé›†ï¼Œ'copy'å¤åˆ¶åˆ°è®­ç»ƒé›†ï¼Œ'delete'åˆ é™¤å¤±è´¥æ ·æœ¬
        output_dir: è¾“å‡ºç›®å½•ï¼ˆä¿å­˜å¤±è´¥æ ·æœ¬ä¿¡æ¯ï¼‰
        backup: æ˜¯å¦å¤‡ä»½åŸæ•°æ®
        enable_replacement: æ˜¯å¦å¯ç”¨æ›¿æ¢åŠŸèƒ½ï¼ˆæ¯ç§»åŠ¨ä¸€ä¸ªå¤±è´¥æ ·æœ¬ï¼Œä»è®­ç»ƒé›†ä¸­ç§»åŠ¨ä¸€ä¸ªé€šè¿‡éªŒè¯çš„æ ·æœ¬åˆ°éªŒè¯é›†ï¼‰
        include_classes: ç±»åˆ«ç™½åå• [0, 1, 2, ...]ï¼Œåªå¤„ç†åŒ…å«è¿™äº›ç±»åˆ«çš„æ ·æœ¬ï¼ŒNone æˆ– [] è¡¨ç¤ºå¤„ç†æ‰€æœ‰æ ·æœ¬

    Returns:
        å¤„ç†ç»Ÿè®¡ä¿¡æ¯
    """
    from ultralytics import YOLO

    print("\n" + "=" * 80)
    action_text = "ç§»åŠ¨åˆ°è®­ç»ƒé›†" if action == 'move' else "åˆ é™¤"
    print(f"ğŸ¯ éªŒè¯é›†å¤±è´¥æ ·æœ¬å¤„ç† - {action_text}")
    if enable_replacement:
        print(f"ğŸ”„ å·²å¯ç”¨æ›¿æ¢åŠŸèƒ½ - ä¿æŒæ•°æ®é›†æ¯”ä¾‹")
    print("=" * 80)

    # åŠ è½½é…ç½®
    config = load_dataset_config(data_yaml_path)
    yaml_dir = Path(data_yaml_path).parent

    val_images_rel = config.get('val', 'images/val')
    val_images_path = yaml_dir / val_images_rel

    print(f"ğŸ“‚ éªŒè¯é›†è·¯å¾„: {val_images_path}")
    print(f"ğŸ² æ“ä½œæ¦‚ç‡: {action_prob:.1%}")
    print(f"âš™ï¸  IoUé˜ˆå€¼: {iou_threshold:.2f}")
    if include_classes:
        print(f"ğŸ·ï¸  ç±»åˆ«ç™½åå•: {include_classes}")
    if enable_replacement:
        print(f"ğŸ”„ æ›¿æ¢æ¨¡å¼: å¯ç”¨")

    if not val_images_path.exists():
        print(f"âŒ éªŒè¯é›†è·¯å¾„ä¸å­˜åœ¨: {val_images_path}")
        return {}

    # åŠ è½½æ¨¡å‹
    print(f"\nğŸš€ åŠ è½½æ¨¡å‹: {model_path}")
    try:
        model = YOLO(model_path)
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return {}

    # å¦‚æœå¯ç”¨æ›¿æ¢åŠŸèƒ½ï¼Œé¢„å…ˆæ‰«æè®­ç»ƒé›†
    train_samples = {}
    if enable_replacement and action == 'move':
        train_samples = scan_training_samples(config, yaml_dir, model, iou_threshold)
        # ç­›é€‰å‡ºé€šè¿‡éªŒè¯çš„è®­ç»ƒé›†æ ·æœ¬
        replaceable_samples = [
            path for path, info in train_samples.items()
            if info['is_pass']
        ]
        print(f"âœ… å¯æ›¿æ¢çš„è®­ç»ƒé›†æ ·æœ¬: {len(replaceable_samples)}ä¸ª")
        if not replaceable_samples:
            print("âš ï¸  æ²¡æœ‰é€šè¿‡éªŒè¯çš„è®­ç»ƒé›†æ ·æœ¬ï¼Œç¦ç”¨æ›¿æ¢åŠŸèƒ½")
            enable_replacement = False

    # éå†éªŒè¯é›†
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
    image_files = [f for f in val_images_path.rglob('*')
                   if f.suffix.lower() in image_extensions and f.is_file()]

    print(f"\nğŸ“Š å¤„ç†{len(image_files)}å¼ å›¾ç‰‡...")

    # åˆ›å»ºæ ‡ç­¾è·¯å¾„å¯¹åº”å…³ç³»
    def get_label_path(image_path: Path) -> Path:
        """æ ¹æ®å›¾ç‰‡è·¯å¾„è·å–å¯¹åº”çš„æ ‡ç­¾è·¯å¾„"""
        rel_path = image_path.relative_to(val_images_path)

        # è·å–æ ‡ç­¾ç›®å½•
        if 'train' in val_images_path.parts:
            labels_dir = val_images_path.parent.parent / 'labels' / 'train'
        elif 'val' in val_images_path.parts:
            labels_dir = val_images_path.parent.parent / 'labels' / 'val'
        else:
            labels_dir = val_images_path.parent.parent / 'labels'

        label_path = labels_dir / rel_path.with_suffix('.txt')
        return label_path

    # æ£€æŸ¥æ¨ç†éªŒè¯
    print("\nğŸ” æ£€æŸ¥æ¨ç†éªŒè¯ç»“æœ...")
    validation_results = {}
    passed_samples = []
    failed_samples = []

    for idx, image_path in enumerate(image_files):
        if (idx + 1) % max(1, len(image_files) // 10) == 0:
            print(f"   è¿›åº¦: {idx + 1}/{len(image_files)}")

        label_path = get_label_path(image_path)

        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç™½åå•ä¸­çš„ç±»åˆ«
        if not has_class_in_whitelist(str(label_path), include_classes):
            # è·³è¿‡ä¸åŒ…å«ç™½åå•ç±»åˆ«çš„æ ·æœ¬
            validation_results[str(image_path)] = {
                'metrics': {},
                'is_pass': None,
                'reason': 'ä¸åœ¨ç±»åˆ«ç™½åå•ä¸­ï¼Œå·²è·³è¿‡',
                'skipped_by_filter': True
            }
            continue

        metrics = calculate_sample_difficulty(image_path, str(label_path), model)
        is_pass, reason = check_inference_pass(metrics, iou_threshold)

        validation_results[str(image_path)] = {
            'metrics': metrics,
            'is_pass': is_pass,
            'reason': reason,
            'skipped_by_filter': False
        }

        if is_pass:
            passed_samples.append(str(image_path))
        else:
            failed_samples.append((str(image_path), reason))

    print(f"\nğŸ“ˆ éªŒè¯ç»Ÿè®¡:")
    print(f"   æ€»æ ·æœ¬æ•°: {len(image_files)}")
    filtered_by_class = len([r for r in validation_results.values() if r.get('skipped_by_filter', False)])
    if filtered_by_class > 0:
        print(f"   ç±»åˆ«è¿‡æ»¤æ’é™¤: {filtered_by_class}")
    print(f"   é€šè¿‡éªŒè¯: {len(passed_samples)}")
    print(f"   éªŒè¯å¤±è´¥: {len(failed_samples)}")

    if failed_samples:
        # ç»Ÿè®¡å¤±è´¥åŸå› 
        failure_reasons = defaultdict(int)
        for _, reason in failed_samples:
            failure_reasons[reason] += 1
        print(f"\n   å¤±è´¥åŸå› åˆ†å¸ƒ:")
        for reason, count in sorted(failure_reasons.items(), key=lambda x: x[1], reverse=True):
            print(f"      {reason}: {count}ä¸ª")

    # å¤‡ä»½åŸæ•°æ® - é€’å¢å¤‡ä»½åç§°
    if backup:
        # æ‰¾åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨çš„å¤‡ä»½ç¼–å·
        backup_counter = 1
        backup_base = val_images_path.parent / f"val_backup"
        labels_backup_base = val_images_path.parent / "labels_backup_val"

        backup_dir = backup_base.with_name(f"{backup_base.name}_{backup_counter}")
        labels_backup_dir = labels_backup_base.with_name(f"{labels_backup_base.name}_{backup_counter}")

        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸å­˜åœ¨çš„ç¼–å·
        while backup_dir.exists() or labels_backup_dir.exists():
            backup_counter += 1
            backup_dir = backup_base.with_name(f"{backup_base.name}_{backup_counter}")
            labels_backup_dir = labels_backup_base.with_name(f"{labels_backup_base.name}_{backup_counter}")

        print(f"\nğŸ’¾ å¤‡ä»½éªŒè¯é›†...")
        print(f"   å›¾åƒå¤‡ä»½: {backup_dir}")
        print(f"   æ ‡ç­¾å¤‡ä»½: {labels_backup_dir}")

        # å¤‡ä»½å›¾åƒ
        shutil.copytree(val_images_path, backup_dir)

        # å¤‡ä»½æ ‡ç­¾
        labels_dir = val_images_path.parent.parent / 'labels' / 'val'
        if labels_dir.exists():
            shutil.copytree(labels_dir, labels_backup_dir)
        else:
            print(f"âš ï¸  æ ‡ç­¾æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {labels_dir}")


    # å¤„ç†éªŒè¯å¤±è´¥çš„æ ·æœ¬
    action_count = 0
    skipped_count = 0
    processed_samples = []
    replacement_count = 0
    replaced_samples = set()  # è®°å½•å·²ç”¨äºæ›¿æ¢çš„è®­ç»ƒé›†æ ·æœ¬

    # è·å–è®­ç»ƒé›†è·¯å¾„ï¼ˆç”¨äºmoveæ“ä½œï¼‰
    train_images_rel = config.get('train', 'images/train')
    train_images_path = yaml_dir / train_images_rel
    # æ„é€ æ ‡ç­¾è·¯å¾„ï¼šdatasets/yolo_format/labels/train (ä¸imagesåŒçº§)
    train_labels_path = yaml_dir / 'labels' / 'train'

    action_verb = "ç§»åŠ¨" if action == 'move' else ("å¤åˆ¶" if action == 'copy' else "åˆ é™¤")
    replacement_verb = ""
    if enable_replacement and action == 'move':
        replacement_verb = " + æ›¿æ¢"
    print(f"\nğŸ“‹ {action_verb}éªŒè¯å¤±è´¥çš„æ ·æœ¬{replacement_verb} (æ¦‚ç‡={action_prob:.1%})...")

    if action in ['move', 'copy']:
        # ç¡®ä¿è®­ç»ƒé›†ç›®å½•å­˜åœ¨
        train_images_path.mkdir(parents=True, exist_ok=True)
        train_labels_path.mkdir(parents=True, exist_ok=True)

    for image_path_str, reason in failed_samples:
        # ä»¥æ“ä½œæ¦‚ç‡éšæœºå†³å®šæ˜¯å¦æ‰§è¡Œæ“ä½œ
        if random.random() < action_prob:
            try:
                image_path_obj = Path(image_path_str)
                label_path = get_label_path(image_path_obj)

                if action == 'move':
                    # ç§»åŠ¨åˆ°è®­ç»ƒé›†
                    new_image_path = train_images_path / image_path_obj.name
                    new_label_path = train_labels_path / label_path.name

                    if image_path_obj.exists():
                        shutil.move(str(image_path_obj), str(new_image_path))
                    if label_path.exists():
                        shutil.move(str(label_path), str(new_label_path))

                    action_count += 1

                    # æ‰§è¡Œæ›¿æ¢æ“ä½œ
                    if enable_replacement and replaceable_samples:
                        # ç­›é€‰å‡ºæœªè¢«ä½¿ç”¨è¿‡çš„å¯æ›¿æ¢æ ·æœ¬
                        available_samples = [
                            s for s in replaceable_samples
                            if s not in replaced_samples
                        ]

                        if available_samples:
                            # éšæœºé€‰æ‹©ä¸€ä¸ªè®­ç»ƒé›†æ ·æœ¬
                            selected_train_sample = random.choice(available_samples)
                            replaced_samples.add(selected_train_sample)

                            try:
                                selected_path = Path(selected_train_sample)

                                # è·å–å¯¹åº”çš„æ ‡ç­¾è·¯å¾„
                                def get_train_label_path(img_path: Path) -> Path:
                                    rel_path = img_path.relative_to(train_images_path)
                                    label_path = train_labels_path / rel_path.with_suffix('.txt')
                                    return label_path

                                selected_label_path = get_train_label_path(selected_path)

                                # ç§»åŠ¨åˆ°éªŒè¯é›†
                                val_images_path.mkdir(parents=True, exist_ok=True)
                                val_labels_path = yaml_dir / 'labels' / 'val'
                                val_labels_path.mkdir(parents=True, exist_ok=True)

                                new_val_image_path = val_images_path / selected_path.name
                                new_val_label_path = val_labels_path / selected_label_path.name

                                if selected_path.exists():
                                    shutil.move(str(selected_path), str(new_val_image_path))
                                if selected_label_path.exists():
                                    shutil.move(str(selected_label_path), str(new_val_label_path))

                                replacement_count += 1

                            except Exception as e:
                                print(f"âš ï¸  æ›¿æ¢æ“ä½œå¤±è´¥ {selected_train_sample}: {e}")

                elif action == 'copy':
                    # å¤åˆ¶åˆ°è®­ç»ƒé›†ï¼ˆä¿ç•™åŸå§‹éªŒè¯é›†å‰¯æœ¬ï¼‰
                    new_image_path = train_images_path / image_path_obj.name
                    new_label_path = train_labels_path / label_path.name

                    if image_path_obj.exists():
                        shutil.copy2(str(image_path_obj), str(new_image_path))
                    if label_path.exists():
                        shutil.copy2(str(label_path), str(new_label_path))

                    action_count += 1

                elif action == 'delete':
                    # åˆ é™¤
                    if image_path_obj.exists():
                        image_path_obj.unlink()
                    if label_path.exists():
                        label_path.unlink()

                    action_count += 1

                processed_samples.append({
                    'image': str(image_path_obj),
                    'action': action,
                    'failure_reason': reason,
                    'metrics': validation_results[image_path_str]['metrics']
                })

            except Exception as e:
                print(f"âš ï¸  æ“ä½œå¤±è´¥ {image_path_str}: {e}")
        else:
            skipped_count += 1


    # ç»Ÿè®¡ç»“æœ
    remaining_images = len([f for f in val_images_path.rglob('*')
                           if f.suffix.lower() in image_extensions and f.is_file()])

    result = {
        'total_samples': len(image_files),
        'passed_samples': len(passed_samples),
        'failed_samples': len(failed_samples),
        'filtered_by_class': filtered_by_class,
        'action_performed': action_count,
        'action_skipped': skipped_count,
        'replacement_performed': replacement_count,
        'remaining_samples': remaining_images,
        'action_probability': action_prob,
        'action_type': action,
        'iou_threshold': iou_threshold,
        'include_classes': include_classes,
        'enable_replacement': enable_replacement,
        'validation_results': validation_results,
        'processed_sample_details': processed_samples
    }

    # æ‰“å°æ€»ç»“
    print(f"\n{'=' * 80}")
    print(f"âœ… å¤„ç†å®Œæˆ!")
    print(f"{'=' * 80}")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   åŸå§‹æ ·æœ¬: {len(image_files)}")
    if filtered_by_class > 0:
        print(f"   ç±»åˆ«è¿‡æ»¤æ’é™¤: {filtered_by_class}")
    print(f"   é€šè¿‡éªŒè¯: {len(passed_samples)}")
    print(f"   éªŒè¯å¤±è´¥: {len(failed_samples)}")
    action_text = "ç§»åŠ¨" if action == 'move' else ("å¤åˆ¶" if action == 'copy' else "åˆ é™¤")
    print(f"   å®é™…{action_text}: {action_count}")
    print(f"   è·³è¿‡å¤±è´¥æ ·æœ¬: {skipped_count}")
    if enable_replacement:
        print(f"   æ›¿æ¢æ ·æœ¬: {replacement_count}")
    print(f"   å‰©ä½™éªŒè¯é›†æ ·æœ¬: {remaining_images}")
    if len(failed_samples) > 0:
        print(f"   æ€»å¤„ç†æ¯”ä¾‹: {action_count / len(failed_samples) * 100:.1f}% (åŸºäºå¤±è´¥æ ·æœ¬)")
    else:
        print(f"   æ€»å¤„ç†æ¯”ä¾‹: æ— å¤±è´¥æ ·æœ¬")

    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    if output_dir:
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜JSONæŠ¥å‘Š
        report_file = output_path / "filter_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            # è½¬æ¢numpyç±»å‹ä»¥ä¾¿JSONåºåˆ—åŒ–
            serializable_result = {
                k: v for k, v in result.items()
                if k != 'sample_difficulties'
            }
            json.dump(serializable_result, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

    return result

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='éªŒè¯é›†å¤±è´¥æ ·æœ¬å¤„ç† - æ ¹æ®æ¨¡å‹æ¨ç†ç»“æœå¤„ç†éªŒè¯å¤±è´¥çš„æ ·æœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # é»˜è®¤è¡Œä¸ºï¼šç§»åŠ¨100%éªŒè¯å¤±è´¥çš„æ ·æœ¬åˆ°è®­ç»ƒé›†ï¼ˆIoU>0.5åˆ™é€šè¿‡ï¼‰
  python filter_hard_examples.py --data datasets/yolo_format/road.yaml --model runs/detect/train/weights/best.pt

  # å¯ç”¨æ›¿æ¢åŠŸèƒ½ï¼šæ¯ç§»åŠ¨1ä¸ªå¤±è´¥æ ·æœ¬ï¼Œä»è®­ç»ƒé›†ä¸­ç§»åŠ¨1ä¸ªé€šè¿‡éªŒè¯çš„æ ·æœ¬åˆ°éªŒè¯é›†
  python filter_hard_examples.py --data datasets/yolo_format/road.yaml --model best.pt --enable-replacement

  # åªç§»åŠ¨50%éªŒè¯å¤±è´¥çš„æ ·æœ¬ï¼ˆä¿ç•™ä¸€äº›éš¾ä¾‹åœ¨éªŒè¯é›†ï¼‰
  python filter_hard_examples.py --data datasets/yolo_format/road.yaml --model best.pt --action-prob 0.5

  # å¯ç”¨æ›¿æ¢ + 50%æ¦‚ç‡ç§»åŠ¨ï¼šæ¯æ¬¡ç§»åŠ¨éƒ½æ›¿æ¢ï¼Œä½†åªç§»åŠ¨50%çš„å¤±è´¥æ ·æœ¬
  python filter_hard_examples.py --data datasets/yolo_format/road.yaml --model best.pt --enable-replacement --action-prob 0.5

  # æ›´ä¸¥æ ¼çš„éªŒè¯æ ‡å‡†ï¼ˆIoU>0.6ï¼‰ï¼Œå¯ç”¨æ›¿æ¢
  python filter_hard_examples.py --data datasets/yolo_format/road.yaml --model best.pt --iou-threshold 0.6 --enable-replacement

  # å¤åˆ¶éªŒè¯å¤±è´¥çš„æ ·æœ¬åˆ°è®­ç»ƒé›†ï¼ˆä¿ç•™åŸå§‹éªŒè¯é›†å‰¯æœ¬ï¼‰
  python filter_hard_examples.py --data datasets/yolo_format/road.yaml --model best.pt --action copy

  # å¤åˆ¶50%éªŒè¯å¤±è´¥çš„æ ·æœ¬
  python filter_hard_examples.py --data datasets/yolo_format/road.yaml --model best.pt --action copy --action-prob 0.5

  # åˆ é™¤éªŒè¯å¤±è´¥çš„æ ·æœ¬
  python filter_hard_examples.py --data datasets/yolo_format/road.yaml --model best.pt --action delete

  # åˆ é™¤50%éªŒè¯å¤±è´¥çš„æ ·æœ¬
  python filter_hard_examples.py --data datasets/yolo_format/road.yaml --model best.pt --action delete --action-prob 0.5

  # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
  python filter_hard_examples.py --data datasets/yolo_format/road.yaml --model best.pt --output-dir ./filter_reports

  # å®Œæ•´ç¤ºä¾‹ï¼šå¯ç”¨æ›¿æ¢ã€50%æ¦‚ç‡ç§»åŠ¨ã€ä¸¥æ ¼éªŒè¯ã€ä¿å­˜æŠ¥å‘Š
  python filter_hard_examples.py --data datasets/yolo_format/road.yaml --model best.pt \\
    --enable-replacement --action-prob 0.5 --iou-threshold 0.6 --output-dir ./filter_reports

  # åªå¤„ç†åŒ…å«ç±»åˆ«0ï¼ˆè£‚ç¼ï¼‰çš„éªŒè¯å¤±è´¥æ ·æœ¬
  python filter_hard_examples.py --data datasets/yolo_format/road.yaml --model best.pt --include-classes 0

  # åªå¤„ç†åŒ…å«ç±»åˆ«0ï¼ˆè£‚ç¼ï¼‰æˆ–ç±»åˆ«2ï¼ˆå‘æ§½ï¼‰çš„éªŒè¯å¤±è´¥æ ·æœ¬
  python filter_hard_examples.py --data datasets/yolo_format/road.yaml --model best.pt --include-classes 0,2

  # ç±»åˆ«è¿‡æ»¤ + æ›¿æ¢åŠŸèƒ½ï¼šåªå¤„ç†åŒ…å«ç±»åˆ«1çš„æ ·æœ¬ï¼Œå¹¶å¯ç”¨æ›¿æ¢
  python filter_hard_examples.py --data datasets/yolo_format/road.yaml --model best.pt \\
    --include-classes 1 --enable-replacement --action-prob 1.0
        """
    )

    parser.add_argument('--data', type=str, default='datasets/yolo_format/road.yaml',
                       help='æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: datasets/yolo_format/road.yaml)')
    parser.add_argument('--model', type=str, required=True,
                       help='YOLOæ¨¡å‹è·¯å¾„ (å¦‚: runs/detect/train/weights/best.pt)')
    parser.add_argument('--action-prob', type=float, default=1.0,
                       help='æ“ä½œæ¦‚ç‡ [0-1]ï¼ŒéªŒè¯å¤±è´¥çš„æ ·æœ¬ä»¥æ­¤æ¦‚ç‡è¢«å¤„ç† (é»˜è®¤: 1.0=100%%)')
    parser.add_argument('--iou-threshold', type=float, default=0.5,
                       help='IoUé˜ˆå€¼ [0-1]ï¼Œåˆ¤æ–­éªŒè¯æ˜¯å¦é€šè¿‡çš„æ ‡å‡† (é»˜è®¤: 0.5)')
    parser.add_argument('--action', type=str, default='move',
                       choices=['move', 'copy', 'delete'],
                       help='æ“ä½œç±»å‹ï¼šmove=ç§»åŠ¨åˆ°è®­ç»ƒé›† (é»˜è®¤), copy=å¤åˆ¶åˆ°è®­ç»ƒé›†, delete=åˆ é™¤æ ·æœ¬')
    parser.add_argument('--output-dir', type=str, default=None,
                       help='è¾“å‡ºç›®å½•ï¼Œä¿å­˜å¤„ç†æŠ¥å‘Š (å¯é€‰)')
    parser.add_argument('--no-backup', action='store_true',
                       help='ä¸å¤‡ä»½åŸå§‹æ•°æ®')
    parser.add_argument('--enable-replacement', action='store_true',
                       help='å¯ç”¨æ›¿æ¢åŠŸèƒ½ï¼šæ¯ç§»åŠ¨ä¸€ä¸ªéªŒè¯å¤±è´¥æ ·æœ¬ï¼Œä»è®­ç»ƒé›†ä¸­ç§»åŠ¨ä¸€ä¸ªé€šè¿‡éªŒè¯çš„æ ·æœ¬åˆ°éªŒè¯é›†ï¼Œä¿æŒæ•°æ®é›†æ¯”ä¾‹ä¸å˜')
    parser.add_argument('--include-classes', type=str, default=None,
                       help='ç±»åˆ«ç™½åå•ï¼Œé€—å·åˆ†éš”çš„æ•´æ•°åˆ—è¡¨ (å¦‚: 0,2 è¡¨ç¤ºåªå¤„ç†åŒ…å«ç±»åˆ«0æˆ–2çš„æ ·æœ¬)ã€‚é»˜è®¤ä¸ºNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰ç±»åˆ«')

    args = parser.parse_args()

    # æ£€æŸ¥æ–‡ä»¶
    if not Path(args.data).exists():
        print(f"âŒ æ•°æ®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
        return 1

    if not Path(args.model).exists():
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model}")
        return 1

    # éªŒè¯å‚æ•°
    if not (0 <= args.action_prob <= 1):
        print(f"âŒ æ“ä½œæ¦‚ç‡å¿…é¡»åœ¨[0, 1]ä¹‹é—´: {args.action_prob}")
        return 1

    if not (0 <= args.iou_threshold <= 1):
        print(f"âŒ IoUé˜ˆå€¼å¿…é¡»åœ¨[0, 1]ä¹‹é—´: {args.iou_threshold}")
        return 1

    # è§£æç±»åˆ«ç™½åå•
    include_classes = None
    if args.include_classes:
        try:
            include_classes = [int(x.strip()) for x in args.include_classes.split(',')]
            print(f"âœ… å·²è®¾ç½®ç±»åˆ«ç™½åå•: {include_classes}")
        except ValueError:
            print(f"âŒ ç±»åˆ«ç™½åå•æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºæ•´æ•°åˆ—è¡¨ï¼Œå¦‚: 0,1,2")
            return 1

    try:
        result = filter_failed_validations(
            data_yaml_path=args.data,
            model_path=args.model,
            action_prob=args.action_prob,
            iou_threshold=args.iou_threshold,
            action=args.action,
            output_dir=args.output_dir,
            backup=not args.no_backup,
            enable_replacement=args.enable_replacement,
            include_classes=include_classes
        )

        return 0 if result else 1

    except KeyboardInterrupt:
        print("\nâš ï¸  æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
        return 1

    except Exception as e:
        print(f"\nâŒ è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())
