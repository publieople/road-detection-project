#!/usr/bin/env python3
"""
æ¨¡å‹ä¼˜åŒ–å’Œè½»é‡åŒ–è„šæœ¬
åŒ…å«æ¨¡å‹å‰ªæã€é‡åŒ–å’ŒçŸ¥è¯†è’¸é¦ç­‰åŠŸèƒ½
"""

import torch
import torch.nn as nn
from ultralytics import YOLO # pyright: ignore[reportPrivateImportUsage]
from pathlib import Path
import numpy as np
import time

class ModelOptimizer:
    def __init__(self, model_path: str):
        """
        åˆå§‹åŒ–æ¨¡å‹ä¼˜åŒ–å™¨

        Args:
            model_path: åŸå§‹æ¨¡å‹è·¯å¾„
        """
        self.model = YOLO(model_path)
        self.original_model_path = model_path

    def prune_model(self, sparsity: float = 0.1, save_path: str = None): # pyright: ignore[reportArgumentType]
        """
        æ¨¡å‹å‰ªæ - ç§»é™¤ä¸é‡è¦çš„æƒé‡

        Args:
            sparsity: å‰ªææ¯”ä¾‹ (0.1 = ç§»é™¤10%çš„æƒé‡)
            save_path: ä¿å­˜è·¯å¾„

        Returns:
            å‰ªæåçš„æ¨¡å‹è·¯å¾„
        """
        print(f"ğŸ”ª å¼€å§‹æ¨¡å‹å‰ªæï¼Œå‰ªææ¯”ä¾‹: {sparsity:.1%}")

        if save_path is None:
            save_path = str(Path(self.original_model_path).parent / f"pruned_{sparsity:.1f}.pt")

        # è·å–æ¨¡å‹æƒé‡
        model_state = self.model.model.state_dict()

        # è®¡ç®—æƒé‡çš„é‡è¦æ€§ï¼ˆåŸºäºç»å¯¹å€¼ï¼‰
        importance_scores = {}
        for name, param in model_state.items():
            if 'weight' in name and param.dim() > 1:  # åªå‰ªæå·ç§¯å’Œå…¨è¿æ¥å±‚çš„æƒé‡
                importance_scores[name] = torch.abs(param)

        # è®¡ç®—å…¨å±€é˜ˆå€¼
        all_scores = torch.cat([scores.flatten() for scores in importance_scores.values()])
        threshold = torch.quantile(all_scores, sparsity)

        # åº”ç”¨å‰ªæ
        pruned_state = {}
        for name, param in model_state.items():
            if name in importance_scores:
                mask = importance_scores[name] > threshold
                pruned_state[name] = param * mask
            else:
                pruned_state[name] = param

        # ä¿å­˜å‰ªæåçš„æ¨¡å‹
        self.model.model.load_state_dict(pruned_state)
        self.model.save(save_path)

        # è®¡ç®—å‰ªææ•ˆæœ
        original_params = sum(p.numel() for p in self.model.model.parameters())
        pruned_params = sum((p != 0).sum() for p in self.model.model.parameters())
        reduction_ratio = 1 - (pruned_params / original_params)

        print(f"âœ… æ¨¡å‹å‰ªæå®Œæˆ")
        print(f"   åŸå§‹å‚æ•°æ•°é‡: {original_params:,}")
        print(f"   å‰©ä½™å‚æ•°æ•°é‡: {pruned_params:,}")
        print(f"   å‚æ•°å‡å°‘æ¯”ä¾‹: {reduction_ratio:.1%}")
        print(f"   æ¨¡å‹å·²ä¿å­˜: {save_path}")

        return save_path

    def quantize_model(self, save_path: str = None):
        """
        æ¨¡å‹é‡åŒ– - å°†FP32æƒé‡è½¬æ¢ä¸ºINT8

        Args:
            save_path: ä¿å­˜è·¯å¾„

        Returns:
            é‡åŒ–åçš„æ¨¡å‹è·¯å¾„
        """
        print("ğŸ“Š å¼€å§‹æ¨¡å‹é‡åŒ– (INT8)")

        if save_path is None:
            save_path = str(Path(self.original_model_path).parent / "quantized_int8.onnx")

        # å¯¼å‡ºä¸ºONNXæ ¼å¼ï¼ˆåŒ…å«é‡åŒ–ï¼‰
        self.model.export(
            format='onnx',
            simplify=True,
            int8=True
        )

        # è·å–å¯¼å‡ºçš„ONNXæ–‡ä»¶è·¯å¾„
        onnx_path = str(Path(self.original_model_path).parent / "best.onnx")

        # é‡å‘½åä¸ºæŒ‡å®šçš„ä¿å­˜è·¯å¾„
        if onnx_path != save_path:
            import shutil
            shutil.move(onnx_path, save_path)

        print(f"âœ… æ¨¡å‹é‡åŒ–å®Œæˆ")
        print(f"   ONNXæ¨¡å‹å·²ä¿å­˜: {save_path}")

        # è®¡ç®—æ¨¡å‹å¤§å°
        original_size = Path(self.original_model_path).stat().st_size / (1024 * 1024)  # MB
        quantized_size = Path(save_path).stat().st_size / (1024 * 1024)  # MB
        compression_ratio = original_size / quantized_size if quantized_size > 0 else 1

        print(f"   åŸå§‹æ¨¡å‹å¤§å°: {original_size:.1f} MB")
        print(f"   é‡åŒ–æ¨¡å‹å¤§å°: {quantized_size:.1f} MB")
        print(f"   å‹ç¼©æ¯”ä¾‹: {compression_ratio:.1f}x")

        return save_path

    def benchmark_model(self, test_images: list, model_path: str | None = None):
        """
        åŸºå‡†æµ‹è¯• - æµ‹è¯•æ¨¡å‹æ€§èƒ½

        Args:
            test_images: æµ‹è¯•å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            model_path: æ¨¡å‹è·¯å¾„ï¼ˆå¦‚æœä¸ä½¿ç”¨å½“å‰æ¨¡å‹ï¼‰

        Returns:
            æ€§èƒ½æŒ‡æ ‡å­—å…¸
        """
        print("âš¡ å¼€å§‹æ¨¡å‹æ€§èƒ½åŸºå‡†æµ‹è¯•")

        # ä½¿ç”¨æŒ‡å®šæ¨¡å‹æˆ–å½“å‰æ¨¡å‹
        if model_path:
            model = YOLO(model_path)
        else:
            model = self.model

        # æµ‹è¯•æ¨ç†é€Ÿåº¦
        inference_times = []
        preprocess_times = []
        postprocess_times = []

        for img_path in test_images[:10]:  # æµ‹è¯•å‰10å¼ å›¾ç‰‡
            start_time = time.time()

            # æ¨ç†
            results = model(img_path, verbose=False)

            end_time = time.time()
            inference_times.append(end_time - start_time)

        # è®¡ç®—å¹³å‡æ€§èƒ½
        avg_inference_time = np.mean(inference_times) * 1000  # è½¬æ¢ä¸ºms
        fps = 1000 / avg_inference_time

        # æ¨¡å‹å¤§å°
        model_size = Path(model_path or self.original_model_path).stat().st_size / (1024 * 1024)  # MB

        # å‚æ•°æ•°é‡
        param_count = sum(p.numel() for p in model.model.parameters())

        results = {
            'model_path': model_path or self.original_model_path,
            'model_size_mb': model_size,
            'parameter_count': param_count,
            'avg_inference_time_ms': avg_inference_time,
            'fps': fps,
            'test_images_count': len(test_images[:10])
        }

        print("ğŸ“Š åŸºå‡†æµ‹è¯•ç»“æœ:")
        print(f"   æ¨¡å‹å¤§å°: {model_size:.1f} MB")
        print(f"   å‚æ•°æ•°é‡: {param_count:,}")
        print(f"   å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time:.1f} ms")
        print(f"   FPS: {fps:.1f}")

        return results

def main():
    """
    ä¸»å‡½æ•°ï¼šæ¨¡å‹ä¼˜åŒ–æµç¨‹
    """
    print("ğŸš€ é“è·¯ç—…å®³æ£€æµ‹æ¨¡å‹ä¼˜åŒ–å·¥å…·")
    print("=" * 60)

    # åŸå§‹æ¨¡å‹è·¯å¾„ - ä½¿ç”¨è®­ç»ƒç»“æœçš„å®é™…è·¯å¾„
    original_model = "D:/sd-webui-aki-v4.11.1-cu128/runs/detect/train20/weights/best.pt"

    if not Path(original_model).exists():
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {original_model}")
        return

    optimizer = ModelOptimizer(original_model)

    # 1. åŸºå‡†æµ‹è¯•åŸå§‹æ¨¡å‹
    print("\n" + "="*60)
    print("1ï¸âƒ£ åŸå§‹æ¨¡å‹åŸºå‡†æµ‹è¯•")
    test_images = list(Path("datasets/yolo_format/images/val").glob("*.jpg"))[:20]
    if test_images:
        original_results = optimizer.benchmark_model(test_images)
    else:
        print("âš ï¸  æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
        original_results = None

    # 2. æ¨¡å‹é‡åŒ–
    print("\n" + "="*60)
    print("2ï¸âƒ£ æ¨¡å‹é‡åŒ–ä¼˜åŒ–")
    try:
        quantized_path = optimizer.quantize_model()
        print("âœ… é‡åŒ–å®Œæˆ")
    except Exception as e:
        print(f"âŒ é‡åŒ–å¤±è´¥: {e}")
        quantized_path = None

    # 3. åŸºå‡†æµ‹è¯•é‡åŒ–æ¨¡å‹
    if quantized_path and test_images:
        print("\n" + "="*60)
        print("3ï¸âƒ£ é‡åŒ–æ¨¡å‹åŸºå‡†æµ‹è¯•")
        try:
            quantized_results = optimizer.benchmark_model(test_images, quantized_path)

            # æ¯”è¾ƒç»“æœ
            if original_results and quantized_results:
                print("\nğŸ“Š æ€§èƒ½å¯¹æ¯”:")
                print(f"   æ¨¡å‹å¤§å°: {original_results['model_size_mb']:.1f} MB â†’ {quantized_results['model_size_mb']:.1f} MB")
                print(f"   å‹ç¼©æ¯”ä¾‹: {original_results['model_size_mb']/quantized_results['model_size_mb']:.1f}x")
                print(f"   æ¨ç†æ—¶é—´: {original_results['avg_inference_time_ms']:.1f} ms â†’ {quantized_results['avg_inference_time_ms']:.1f} ms")
                print(f"   FPS: {original_results['fps']:.1f} â†’ {quantized_results['fps']:.1f}")
        except Exception as e:
            print(f"âŒ é‡åŒ–æ¨¡å‹åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")

    # 4. æ¨¡å‹å‰ªæï¼ˆå¯é€‰ï¼‰
    print("\n" + "="*60)
    print("4ï¸âƒ£ æ¨¡å‹å‰ªæä¼˜åŒ–")
    try:
        # è½»åº¦å‰ªæ
        pruned_path = optimizer.prune_model(sparsity=0.1)
        print("âœ… å‰ªæå®Œæˆ")

        # åŸºå‡†æµ‹è¯•å‰ªææ¨¡å‹
        if test_images:
            pruned_results = optimizer.benchmark_model(test_images, pruned_path)
    except Exception as e:
        print(f"âŒ å‰ªæå¤±è´¥: {e}")

    print("\n" + "="*60)
    print("ğŸ‰ æ¨¡å‹ä¼˜åŒ–å®Œæˆï¼")
    print("ğŸ’¡ å»ºè®®:")
    print("   - ä½¿ç”¨é‡åŒ–æ¨¡å‹è¿›è¡Œéƒ¨ç½²ï¼Œè·å¾—æ›´å¥½çš„å‹ç¼©æ•ˆæœ")
    print("   - æ ¹æ®å®é™…éœ€æ±‚é€‰æ‹©å‰ªææ¯”ä¾‹")
    print("   - åœ¨ç›®æ ‡ç¡¬ä»¶ä¸Šæµ‹è¯•æœ€ç»ˆæ€§èƒ½")

if __name__ == "__main__":
    main()