#!/usr/bin/env python3
"""
é“è·¯ç—…å®³æ£€æµ‹æ¨¡å‹è®­ç»ƒè„šæœ¬
åŸºäºyolo11è®­ç»ƒä¸“é—¨çš„é“è·¯ç—…å®³æ£€æµ‹æ¨¡å‹
"""

import torch
from ultralytics import YOLO
from pathlib import Path
import yaml
import os

def get_dataset_stats(data_yaml_path: str) -> dict:
    """ä»æ•°æ®é…ç½®æ–‡ä»¶ä¸­è·å–ç»Ÿè®¡ä¿¡æ¯"""
    try:
        with open(data_yaml_path, 'r', encoding='utf-8') as f:
            data_config = yaml.safe_load(f)

        # è·å–ç±»åˆ«ä¿¡æ¯
        nc = data_config.get('nc', 0)
        names = data_config.get('names', [])

        # è®¡ç®—è®­ç»ƒå’ŒéªŒè¯å›¾ç‰‡æ•°é‡
        def count_images_in_path(path_pattern):
            """è®¡ç®—æŒ‡å®šè·¯å¾„æ¨¡å¼ä¸‹çš„å›¾ç‰‡æ•°é‡"""
            if isinstance(path_pattern, list):
                # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå¤„ç†å¤šä¸ªè·¯å¾„
                total_count = 0
                for pattern in path_pattern:
                    path = Path(pattern)
                    if path.exists():
                        if path.is_dir():
                            total_count += len(list(path.rglob('*.jpg')) + list(path.rglob('*.png')) +
                                             list(path.rglob('*.jpeg')) + list(path.rglob('*.JPG')))
                        else:
                            # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œå¯èƒ½æ˜¯åŒ…å«å›¾ç‰‡è·¯å¾„çš„txtæ–‡ä»¶
                            with open(path, 'r') as f:
                                total_count += len([line for line in f.readlines() if line.strip()])
                return total_count
            else:
                # å•ä¸ªè·¯å¾„
                path = Path(path_pattern)
                if path.exists():
                    if path.is_dir():
                        return len(list(path.rglob('*.jpg')) + list(path.rglob('*.png')) +
                                 list(path.rglob('*.jpeg')) + list(path.rglob('*.JPG')))
                    else:
                        # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œå¯èƒ½æ˜¯åŒ…å«å›¾ç‰‡è·¯å¾„çš„txtæ–‡ä»¶
                        with open(path, 'r') as f:
                            return len([line for line in f.readlines() if line.strip()])
                return 0

        train_count = count_images_in_path(data_config.get('train', ''))
        val_count = count_images_in_path(data_config.get('val', ''))

        return {
            'train_count': train_count,
            'val_count': val_count,
            'num_classes': nc,
            'class_names': names
        }
    except Exception as e:
        print(f"âš ï¸  è·å–æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        return {
            'train_count': 0,
            'val_count': 0,
            'num_classes': 0,
            'class_names': []
        }

def setup_training():
    """é…ç½®è®­ç»ƒç¯å¢ƒå’Œå‚æ•°"""

    # æ£€æŸ¥GPUå¯ç”¨æ€§
    if torch.cuda.is_available():
        print(f"âœ… GPUå¯ç”¨: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ”¥ CUDAç‰ˆæœ¬: {torch.version.cuda}")
        device = 'cuda'
    else:
        print("âš ï¸  GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUè®­ç»ƒ")
        device = 'cpu'

    return device

def train_model(data_yaml_path: str, model_size: str = 'n', epochs: int = 100, img_size: int = 1280, resume: bool = False):
    """
    è®­ç»ƒYOLOæ¨¡å‹

    Args:
        data_yaml_path: æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„
        model_size: æ¨¡å‹å¤§å° ('n', 's', 'm', 'l', 'x')
        epochs: è®­ç»ƒè½®æ•°
        img_size: è¾“å…¥å›¾åƒå°ºå¯¸
        resume: æ˜¯å¦ä»ä¸Šæ¬¡ä¸­æ–­å¤„æ¢å¤è®­ç»ƒ
    """

    device = setup_training()

    if resume:
        # æ¢å¤è®­ç»ƒæ¨¡å¼
        print("ğŸ”„ æ£€æµ‹æ˜¯å¦å­˜åœ¨ä¸­æ–­çš„è®­ç»ƒï¼Œå°è¯•æ¢å¤...")

        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¸Šæ¬¡è®­ç»ƒçš„æƒé‡æ–‡ä»¶
        possible_weights = [
            'runs/detect/train/weights/last.pt',  # é»˜è®¤è®­ç»ƒè·¯å¾„
            'runs/detect/train2/weights/last.pt', # ç¬¬äºŒæ¬¡è®­ç»ƒè·¯å¾„
            'runs/detect/train3/weights/last.pt', # ç¬¬ä¸‰æ¬¡è®­ç»ƒè·¯å¾„
        ]

        resume_path = None
        for weight_path in possible_weights:
            if Path(weight_path).exists():
                resume_path = weight_path
                break

        if resume_path:
            print(f"âœ… æ‰¾åˆ°ä¸­æ–­çš„è®­ç»ƒæƒé‡: {resume_path}")
            model = YOLO(resume_path)
            print("ğŸš€ ä»ä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­è®­ç»ƒ...")
        else:
            print("âš ï¸  æœªæ‰¾åˆ°å¯æ¢å¤çš„æƒé‡æ–‡ä»¶ï¼Œå¼€å§‹æ–°çš„è®­ç»ƒ...")
            # é€‰æ‹©é¢„è®­ç»ƒæ¨¡å‹
            model_name = f'yolo11{model_size}.pt'
            print(f"ğŸ“¦ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {model_name}")
            model = YOLO(model_name)
    else:
        # æ­£å¸¸è®­ç»ƒæ¨¡å¼
        # é€‰æ‹©é¢„è®­ç»ƒæ¨¡å‹
        model_name = f'yolo11{model_size}.pt'
        print(f"ğŸ“¦ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {model_name}")
        model = YOLO(model_name)

    # è®­ç»ƒé…ç½®
    training_config = {
        'data': data_yaml_path,
        'epochs': epochs,
        'imgsz': img_size,
        'batch': 16,                              # æ‰¹æ¬¡å¤§å°ï¼Œå¯æ ¹æ®GPUå†…å­˜è°ƒæ•´
        'workers': 4,                            # æ•°æ®åŠ è½½çº¿ç¨‹æ•°
        'cache': False,                          # æ˜¯å¦ç¼“å­˜æ•°æ®é›†

        'device': device,
        'optimizer': 'AdamW',
        'lr0': 0.001,                            # åˆå§‹å­¦ä¹ ç‡
        'lrf': 0.01,                             # æœ€ç»ˆå­¦ä¹ ç‡å€æ•°
        'momentum': 0.937,
        'weight_decay': 0.0005,
        'warmup_epochs': 10,                     # é¢„çƒ­è½®æ•°
        'warmup_momentum': 0.8,
        'box': 7.5,                              # box losså¢ç›Š
        'cls': 0.5,                              # cls losså¢ç›Š
        'dfl': 1.5,                              # dfl losså¢ç›Š

        'hsv_h': 0.015,                          # HSVè‰²è°ƒå¢å¼º
        'hsv_s': 0.7,                            # HSVé¥±å’Œåº¦å¢å¼º
        'hsv_v': 0.4,                            # HSVæ˜åº¦å¢å¼º
        'degrees': 5.0,                          # æ—‹è½¬å¢å¼º
        'scale': 0.7,                            # ç¼©æ”¾å¢å¼º
        'shear': 0.0,                            # å‰ªåˆ‡å¢å¼º
        'perspective': 0.0005,                   # é€è§†å¢å¼º
        'fliplr': 0.8,                           # å·¦å³ç¿»è½¬
        'flipud': 0.3,                           # ä¸Šä¸‹ç¿»è½¬
        'translate': 0.2,                        # å¹³ç§»å¢å¼º
        'mosaic': 0.8,                           # mosaicå¢å¼º
        'mixup': 0.3,                            # mixupå¢å¼º
        'copy_paste': 0.2,                       # å¤åˆ¶ç²˜è´´å¢å¼º
        'auto_augment': 'rand-m9-mstd0.5-inc1',  # è‡ªåŠ¨å¢å¼ºç­–ç•¥
        'erasing': 0.6,                          # éšæœºæ“¦é™¤

        'crop_fraction': 1.0,                    # è£å‰ªæ¯”ä¾‹
        "amp": True,                             # æ··åˆç²¾åº¦åŠ é€Ÿ

        'close_mosaic': 10,                      # å…³é—­mosaicçš„æœ€åè½®æ•°
        'overlap_mask': False,                   # æ˜¯å¦ä½¿ç”¨é‡å æ©ç 
        'single_cls': False,                     # æ˜¯å¦ä¸ºå•ç±»åˆ«æ£€æµ‹
        'patience': 50,                          # æ—©åœè€å¿ƒå€¼
        'cos_lr': True,                          # ä½¿ç”¨ä½™å¼¦é€€ç«å­¦ä¹ ç‡
    }

    print("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
    print(f"ğŸ“Š è®­ç»ƒè½®æ•°: {epochs}")
    print(f"ğŸ“ å›¾åƒå°ºå¯¸: {img_size}")
    print(f"ğŸ”§ è®¾å¤‡: {device}")

    # å¼€å§‹è®­ç»ƒ
    if resume and resume_path:
        # æ¢å¤è®­ç»ƒæ¨¡å¼
        training_config['resume'] = True
        results = model.train(**training_config)
    else:
        # æ­£å¸¸è®­ç»ƒæ¨¡å¼
        results = model.train(**training_config)

    # ä¿å­˜è®­ç»ƒç»“æœ
    print("âœ… è®­ç»ƒå®Œæˆ!")
    if results and hasattr(results, 'save_dir'):
        print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: {Path(results.save_dir).resolve()}")
    else:
        print("ğŸ“ æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œä¿å­˜è·¯å¾„ä¿¡æ¯ä¸å¯ç”¨")

    return model, results

def validate_model(model, data_yaml_path: str):
    """éªŒè¯æ¨¡å‹æ€§èƒ½"""
    print("ğŸ” éªŒè¯æ¨¡å‹æ€§èƒ½...")

    # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
    metrics = model.val(data=data_yaml_path)

    print("ğŸ“Š éªŒè¯ç»“æœ:")
    print(f"   mAP@0.5: {metrics.box.map50:.3f}")
    print(f"   mAP@0.5:0.95: {metrics.box.map:.3f}")
    print(f"   å¹³å‡ç²¾ç¡®ç‡: {metrics.box.mp:.3f}")
    print(f"   å¹³å‡å¬å›ç‡: {metrics.box.mr:.3f}")

    return metrics

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    # å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description='é“è·¯ç—…å®³æ£€æµ‹æ¨¡å‹è®­ç»ƒ')
    parser.add_argument('--resume', action='store_true', help='ä»ä¸Šæ¬¡ä¸­æ–­å¤„æ¢å¤è®­ç»ƒ')
    parser.add_argument('--data', type=str, default='datasets/yolo_format/road.yaml', help='æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--model-size', type=str, default='n', choices=['n', 's', 'm', 'l', 'x'], help='æ¨¡å‹å¤§å°')
    parser.add_argument('--epochs', type=int, default=50, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--img-size', type=int, default=640, help='è¾“å…¥å›¾åƒå°ºå¯¸')

    args = parser.parse_args()

    # æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„
    data_yaml = args.data

    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(data_yaml).exists():
        print(f"âŒ æ•°æ®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {data_yaml}")
        return

    print("ğŸ›£ï¸  é“è·¯ç—…å®³æ£€æµ‹æ¨¡å‹è®­ç»ƒ")
    print("=" * 50)

    if args.resume:
        print("ğŸ”„ å·²å¯ç”¨è®­ç»ƒæ¢å¤æ¨¡å¼")

    print(f"ğŸ“Š é…ç½®: æ¨¡å‹={args.model_size}, è½®æ•°={args.epochs}, å°ºå¯¸={args.img_size}")

    try:
        # è®­ç»ƒæ¨¡å‹
        model, training_results = train_model(
            data_yaml_path=data_yaml,
            model_size=args.model_size,
            epochs=args.epochs,          # è®­ç»ƒ50è½®
            img_size=args.img_size,      # è¾“å…¥å›¾åƒå°ºå¯¸
            resume=args.resume           # æ˜¯å¦æ¢å¤è®­ç»ƒ
        )

        # éªŒè¯æ¨¡å‹
        metrics = validate_model(model, data_yaml)

        # è·å–æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        dataset_stats = get_dataset_stats(data_yaml)

        print("\nğŸ‰ è®­ç»ƒæµç¨‹å®Œæˆ!")
        print("ğŸ“‹ æ€»ç»“:")
        print(f"   - è®­ç»ƒå›¾ç‰‡: {dataset_stats['train_count']}å¼ ")
        print(f"   - éªŒè¯å›¾ç‰‡: {dataset_stats['val_count']}å¼ ")
        print(f"   - ç—…å®³ç±»åˆ«: {dataset_stats['num_classes']}ç±»")
        if dataset_stats['class_names']:
            print(f"   - ç±»åˆ«åç§°: {', '.join(dataset_stats['class_names'])}")
        print(f"   - æœ€ä½³mAP@0.5: {metrics.box.map50:.3f}")

        # å¯¼å‡ºæ¨¡å‹
        print("\nğŸ’¾ å¯¼å‡ºè®­ç»ƒå¥½çš„æ¨¡å‹...")
        model.export(format='onnx', simplify=True)

    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        raise

if __name__ == "__main__":
    main()