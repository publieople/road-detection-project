#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é“è·¯ç—…å®³æ£€æµ‹æ¨¡å‹è®­ç»ƒè„šæœ¬ - é‡æ„ç‰ˆ
åŸºäºæ¨¡å—åŒ–æ¶æ„çš„ç»Ÿä¸€è®­ç»ƒå…¥å£
"""

import argparse
import sys
from pathlib import Path

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from road_detection.training import RoadDamageTrainer, create_training_config
from road_detection.utils import setup_chinese_fonts

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    setup_chinese_fonts()
    
    # å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(
        description='é“è·¯ç—…å®³æ£€æµ‹æ¨¡å‹è®­ç»ƒ - æ¨¡å—åŒ–ç‰ˆæœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # æ ‡å‡†è®­ç»ƒ
  python train.py --config-type standard --data datasets/yolo_format/road.yaml
  
  # ä¼˜åŒ–è®­ç»ƒï¼ˆé’ˆå¯¹RDD2022ï¼‰
  python train.py --config-type optimized --data datasets/yolo_format/road.yaml
  
  # å¿«é€Ÿè®­ç»ƒ
  python train.py --config-type fast --epochs 50 --model-size n
  
  # æ¢å¤è®­ç»ƒ
  python train.py --resume --resume-path runs/detect/train/weights/last.pt
  
  # è‡ªå®šä¹‰é…ç½®
  python train.py --config-type custom --epochs 200 --model-size m --lr0 0.001
        """
    )
    
    # åŸºç¡€å‚æ•°
    parser.add_argument('--data', type=str, default='datasets/yolo_format/road.yaml',
                       help='æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: datasets/yolo_format/road.yaml)')
    parser.add_argument('--config-type', type=str, default='standard',
                       choices=['standard', 'optimized', 'balanced', 'fast', 'custom'],
                       help='é…ç½®ç±»å‹ (é»˜è®¤: standard)')
    parser.add_argument('--dataset-type', type=str, default='rdd2022',
                       choices=['rdd2022', 'rdd2020', 'custom'],
                       help='æ•°æ®é›†ç±»å‹ (é»˜è®¤: rdd2022)')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--model-size', type=str, default='n',
                       choices=['n', 's', 'm', 'l', 'x'],
                       help='æ¨¡å‹å¤§å° (é»˜è®¤: n)')
    parser.add_argument('--epochs', type=int, default=None,
                       help='è®­ç»ƒè½®æ•° (æ ¹æ®é…ç½®ç±»å‹è‡ªåŠ¨è®¾ç½®)')
    parser.add_argument('--img-size', type=int, default=640,
                       help='è¾“å…¥å›¾åƒå°ºå¯¸ (é»˜è®¤: 640)')
    parser.add_argument('--batch-size', type=int, default=16,
                       help='æ‰¹æ¬¡å¤§å° (é»˜è®¤: 16)')
    
    # ä¼˜åŒ–å™¨å‚æ•°
    parser.add_argument('--optimizer', type=str, default=None,
                       choices=['SGD', 'AdamW'],
                       help='ä¼˜åŒ–å™¨ç±»å‹')
    parser.add_argument('--lr0', type=float, default=None,
                       help='åˆå§‹å­¦ä¹ ç‡')
    parser.add_argument('--lrf', type=float, default=None,
                       help='æœ€ç»ˆå­¦ä¹ ç‡å€æ•°')
    
    # è®­ç»ƒæ§åˆ¶
    parser.add_argument('--resume', action='store_true',
                       help='ä»ä¸Šæ¬¡ä¸­æ–­å¤„æ¢å¤è®­ç»ƒ')
    parser.add_argument('--resume-path', type=str, default=None,
                       help='æŒ‡å®šæ¢å¤è®­ç»ƒçš„æƒé‡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--device', type=str, default='auto',
                       choices=['auto', 'cuda', 'cpu'],
                       help='è®­ç»ƒè®¾å¤‡ (é»˜è®¤: auto)')
    
    # å¢å¼ºå‚æ•°
    parser.add_argument('--mosaic', type=float, default=None,
                       help='Mosaicå¢å¼ºå¼ºåº¦')
    parser.add_argument('--mixup', type=float, default=None,
                       help='MixUpå¢å¼ºæ¯”ä¾‹')
    parser.add_argument('--degrees', type=float, default=None,
                       help='æ—‹è½¬å¢å¼ºè§’åº¦')
    
    # æ€§èƒ½ç›®æ ‡
    parser.add_argument('--target-map50', type=float, default=0.80,
                       help='ç›®æ ‡mAP@0.5 (é»˜è®¤: 0.80)')
    
    # è¾“å‡ºæ§åˆ¶
    parser.add_argument('--save-dir', type=str, default=None,
                       help='ç»“æœä¿å­˜ç›®å½•')
    parser.add_argument('--export-format', type=str, default='onnx',
                       choices=['onnx', 'torchscript', 'tensorrt'],
                       help='æ¨¡å‹å¯¼å‡ºæ ¼å¼ (é»˜è®¤: onnx)')
    parser.add_argument('--no-export', action='store_true',
                       help='è·³è¿‡æ¨¡å‹å¯¼å‡º')
    
    # åˆ†æé€‰é¡¹
    parser.add_argument('--analyze-dataset', action='store_true',
                       help='è¯¦ç»†åˆ†ææ•°æ®é›†')
    parser.add_argument('--generate-report', action='store_true',
                       help='ç”Ÿæˆè¯¦ç»†è®­ç»ƒæŠ¥å‘Š')
    
    args = parser.parse_args()
    
    # æ‰“å°æ¬¢è¿ä¿¡æ¯
    print("\n" + "=" * 80)
    print("ğŸ›£ï¸  é“è·¯ç—…å®³æ£€æµ‹æ¨¡å‹è®­ç»ƒç³»ç»Ÿ - æ¨¡å—åŒ–ç‰ˆæœ¬")
    print("=" * 80)
    print(f"ğŸ“‹ é…ç½®ç±»å‹: {args.config_type}")
    print(f"ğŸ“Š æ•°æ®é›†: {args.data}")
    print(f"ğŸ¯ ç›®æ ‡mAP@0.5: {args.target_map50}")
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    if not Path(args.data).exists():
        print(f"âŒ æ•°æ®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
        return 1
    
    try:
        # åˆ›å»ºè®­ç»ƒé…ç½®
        print(f"\nğŸ”§ åˆ›å»ºè®­ç»ƒé…ç½®...")
        
        if args.config_type == 'custom':
            # è‡ªå®šä¹‰é…ç½®
            config_kwargs = {
                'data_yaml_path': args.data,
                'model_size': args.model_size,
                'device': args.device,
                'target_map50': args.target_map50
            }
            
            # æ·»åŠ éNoneçš„å‚æ•°
            if args.epochs is not None:
                config_kwargs['epochs'] = args.epochs
            if args.img_size is not None:
                config_kwargs['img_size'] = args.img_size
            if args.batch_size is not None:
                config_kwargs['batch_size'] = args.batch_size
            if args.optimizer is not None:
                config_kwargs['optimizer'] = args.optimizer
            if args.lr0 is not None:
                config_kwargs['lr0'] = args.lr0
            if args.lrf is not None:
                config_kwargs['lrf'] = args.lrf
            if args.mosaic is not None:
                config_kwargs['mosaic'] = args.mosaic
            if args.mixup is not None:
                config_kwargs['mixup'] = args.mixup
            if args.degrees is not None:
                config_kwargs['degrees'] = args.degrees
            
            config = create_training_config('standard', **config_kwargs)
        else:
            # ä½¿ç”¨é¢„è®¾é…ç½®
            config = create_training_config(
                config_type=args.config_type,
                data_yaml_path=args.data,
                model_size=args.model_size,
                device=args.device,
                target_map50=args.target_map50
            )
            
            # è¦†ç›–ç‰¹å®šå‚æ•°
            if args.epochs is not None:
                config.epochs = args.epochs
            if args.img_size is not None:
                config.img_size = args.img_size
            if args.batch_size is not None:
                config.batch_size = args.batch_size
        
        # åˆ†æé€‰é¡¹é€šè¿‡ä¼˜åŒ–é…ç½®è‡ªåŠ¨å¯ç”¨ï¼Œä¸éœ€è¦é¢å¤–è®¾ç½®
        # ä¼˜åŒ–é…ç½®ï¼ˆAdamW + é«˜cls_gainï¼‰ä¼šè‡ªåŠ¨å¯ç”¨æ•°æ®é›†åˆ†æ
        
        # åˆ›å»ºè®­ç»ƒå™¨
        print("\nğŸ—ï¸  åˆ›å»ºè®­ç»ƒå™¨...")
        trainer = RoadDamageTrainer(config)
        
        # æ‰§è¡Œè®­ç»ƒæµç¨‹
        print("\nğŸš€ å¼€å§‹è®­ç»ƒæµç¨‹...")
        
        # å‡†å¤‡é˜¶æ®µ
        dataset_stats = trainer.prepare_training()
        
        # åˆ›å»ºæˆ–åŠ è½½æ¨¡å‹
        model = trainer.create_or_load_model(resume_path=args.resume_path)
        
        # è®­ç»ƒ
        model, training_results = trainer.train(resume=args.resume)
        
        # éªŒè¯
        validation_results = trainer.validate(save_dir=args.save_dir)
        
        # å¯¼å‡ºæ¨¡å‹
        if not args.no_export:
            export_path = trainer.export_model(format=args.export_format)
            print(f"ğŸ’¾ æ¨¡å‹å·²å¯¼å‡º: {export_path}")
        
        # ç”ŸæˆæŠ¥å‘Š
        if args.generate_report:
            if args.save_dir:
                report_path = Path(args.save_dir) / "training_report.txt"
            else:
                report_path = "training_report.txt"
            trainer.save_training_report(str(report_path))
        
        # æ‰“å°æ€»ç»“
        print("\n" + "=" * 80)
        print("ğŸ‰ è®­ç»ƒæµç¨‹å®Œæˆ!")
        print("=" * 80)
        print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
        print(f"   è®­ç»ƒå›¾ç‰‡: {dataset_stats['train_count']} å¼ ")
        print(f"   éªŒè¯å›¾ç‰‡: {dataset_stats['val_count']} å¼ ")
        print(f"   ç±»åˆ«æ•°é‡: {dataset_stats['num_classes']}")
        print(f"   ç±»åˆ«åç§°: {', '.join(dataset_stats['class_names'])}")
        print(f"\nğŸ¯ éªŒè¯ç»“æœ:")
        print(f"   mAP@0.5: {validation_results['mAP50']:.3f}")
        print(f"   mAP@0.5:0.95: {validation_results['mAP5095']:.3f}")
        
        # æ£€æŸ¥ç›®æ ‡è¾¾æˆ
        if validation_results['mAP50'] >= args.target_map50:
            print(f"âœ… ç›®æ ‡è¾¾æˆï¼æ¨¡å‹å‡†ç¡®ç‡ â‰¥ {args.target_map50:.0%}")
        else:
            print(f"âš ï¸  æœªè¾¾ç›®æ ‡ã€‚å½“å‰å‡†ç¡®ç‡: {validation_results['mAP50']:.1%}, ç›®æ ‡: {args.target_map50:.0%}")
        
        print("\nğŸ’¡ æç¤º:")
        print("   - ä½¿ç”¨ analyze_training_results.py åˆ†æè®­ç»ƒå†å²")
        print("   - ä½¿ç”¨ model_optimization.py è¿›è¡Œæ¨¡å‹ä¼˜åŒ–")
        print("   - ä½¿ç”¨ detect.py è¿›è¡Œæ¨¡å‹æ¨ç†æµ‹è¯•")
        
        return 0
        
    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        return 1
        
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())