#!/usr/bin/env python3
"""
é“è·¯ç—…å®³æ£€æµ‹æ¨¡å‹å¿«é€Ÿè®­ç»ƒæµ‹è¯•è„šæœ¬
åœ¨å°è§„æ¨¡æ•°æ®é›†ä¸ŠåŸºäºYOLO11nè¿›è¡Œå¿«é€Ÿè®­ç»ƒæµ‹è¯•
"""

import torch
from ultralytics import YOLO
from pathlib import Path
import yaml
import os
import argparse
import random
import shutil
from sklearn.model_selection import train_test_split


def create_subset_dataset(original_data_yaml: str, subset_ratio: float = 0.1, output_dir: str = "datasets/test_subset"):
    """
    åˆ›å»ºåŸå§‹æ•°æ®é›†çš„å°è§„æ¨¡å­é›†ç”¨äºå¿«é€Ÿè®­ç»ƒæµ‹è¯•

    Args:
        original_data_yaml: åŸå§‹æ•°æ®é›†YAMLé…ç½®æ–‡ä»¶è·¯å¾„
        subset_ratio: å­é›†å åŸå§‹æ•°æ®çš„æ¯”ä¾‹
        output_dir: è¾“å‡ºç›®å½•

    Returns:
        str: æ–°çš„å­é›†æ•°æ®é›†YAMLé…ç½®æ–‡ä»¶è·¯å¾„
    """
    print(f"ğŸ“¦ åˆ›å»ºå°è§„æ¨¡æ•°æ®é›†å­é›† (æ¯”ä¾‹: {subset_ratio})...")

    # è¯»å–åŸå§‹æ•°æ®é…ç½®
    with open(original_data_yaml, 'r', encoding='utf-8') as f:
        original_config = yaml.safe_load(f)

    # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    images_dir = output_path / "images"
    labels_dir = output_path / "labels"
    images_train_dir = images_dir / "train"
    images_val_dir = images_dir / "val"
    labels_train_dir = labels_dir / "train"
    labels_val_dir = labels_dir / "val"

    for dir_path in [images_train_dir, images_val_dir, labels_train_dir, labels_val_dir]:
        dir_path.mkdir(parents=True, exist_ok=True)

    # å¤„ç†è®­ç»ƒé›†
    original_train_path = Path(original_config['path']) / original_config['train']
    train_images = list(original_train_path.rglob("*.jpg")) + \
                   list(original_train_path.rglob("*.png")) + \
                   list(original_train_path.rglob("*.jpeg"))

    # æ ¹æ®æ¯”ä¾‹é€‰å–å­é›†
    subset_train_size = max(10, int(len(train_images) * subset_ratio))  # è‡³å°‘10å¼ å›¾ç‰‡
    subset_train_images = random.sample(train_images, min(subset_train_size, len(train_images)))

    # å¤åˆ¶è®­ç»ƒå›¾ç‰‡å’Œæ ‡ç­¾
    for img_path in subset_train_images:
        # å¤åˆ¶å›¾ç‰‡
        dst_img_path = images_train_dir / img_path.name
        shutil.copy(img_path, dst_img_path)

        # æŸ¥æ‰¾å¹¶å¤åˆ¶å¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶
        label_path = Path(str(img_path).replace("images", "labels")).with_suffix(".txt")
        if label_path.exists():
            dst_label_path = labels_train_dir / label_path.name
            shutil.copy(label_path, dst_label_path)

    print(f"âœ… è®­ç»ƒé›†: å¤åˆ¶äº† {len(subset_train_images)} å¼ å›¾ç‰‡")

    # å¤„ç†éªŒè¯é›†
    original_val_path = Path(original_config['path']) / original_config['val']
    val_images = list(original_val_path.rglob("*.jpg")) + \
                 list(original_val_path.rglob("*.png")) + \
                 list(original_val_path.rglob("*.jpeg"))

    # æ ¹æ®æ¯”ä¾‹é€‰å–å­é›†
    subset_val_size = max(5, int(len(val_images) * subset_ratio))  # è‡³å°‘5å¼ å›¾ç‰‡
    subset_val_images = random.sample(val_images, min(subset_val_size, len(val_images)))

    # å¤åˆ¶éªŒè¯å›¾ç‰‡å’Œæ ‡ç­¾
    for img_path in subset_val_images:
        # å¤åˆ¶å›¾ç‰‡
        dst_img_path = images_val_dir / img_path.name
        shutil.copy(img_path, dst_img_path)

        # æŸ¥æ‰¾å¹¶å¤åˆ¶å¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶
        label_path = Path(str(img_path).replace("images", "labels")).with_suffix(".txt")
        if label_path.exists():
            dst_label_path = labels_val_dir / label_path.name
            shutil.copy(label_path, dst_label_path)

    print(f"âœ… éªŒè¯é›†: å¤åˆ¶äº† {len(subset_val_images)} å¼ å›¾ç‰‡")

    # åˆ›å»ºæ–°çš„YAMLé…ç½®æ–‡ä»¶
    subset_config = {
        'path': str(output_path.absolute()),
        'train': 'images/train',
        'val': 'images/val',
        'nc': original_config['nc'],
        'names': original_config['names']
    }

    subset_yaml_path = output_path / "test_dataset.yaml"
    with open(subset_yaml_path, 'w', encoding='utf-8') as f:
        yaml.dump(subset_config, f, allow_unicode=True)

    print(f"âœ… å­é›†æ•°æ®é›†åˆ›å»ºå®Œæˆ: {subset_yaml_path}")
    return str(subset_yaml_path)


def setup_training():
    """é…ç½®è®­ç»ƒç¯å¢ƒå’Œå‚æ•°"""
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    if torch.cuda.is_available():
        print(f"âœ… GPUå¯ç”¨: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ”¥ CUDAç‰ˆæœ¬: {torch.version.cuda}")
        device = 'cuda'
    else:
        print("âš ï¸  GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUè®­ç»ƒ")
        device = 'cpu'

    return device


def train_model_fast(data_yaml_path: str, epochs: int = 10, img_size: int = 640):
    """
    å¿«é€Ÿè®­ç»ƒYOLOæ¨¡å‹ç”¨äºæµ‹è¯•

    Args:
        data_yaml_path: æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„
        epochs: è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤10è½®ï¼‰
        img_size: è¾“å…¥å›¾åƒå°ºå¯¸
    """
    device = setup_training()

    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    model_name = "yolo11n.pt"
    print(f"ğŸ“¦ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {model_name}")
    model = YOLO(model_name)

    # å¿«é€Ÿè®­ç»ƒé…ç½®
    training_config = {
        'data': data_yaml_path,
        'epochs': epochs,
        'imgsz': img_size,
        'batch': 4,              # è¾ƒå°çš„æ‰¹æ¬¡å¤§å°
        'device': device,
        'optimizer': 'SGD',      # ä½¿ç”¨ç®€å•ä¼˜åŒ–å™¨
        'lr0': 0.01,             # è¾ƒé«˜çš„åˆå§‹å­¦ä¹ ç‡
        'lrf': 0.01,             # æœ€ç»ˆå­¦ä¹ ç‡å€æ•°
        'momentum': 0.937,
        'weight_decay': 0.0005,
        'warmup_epochs': 1,      # å‡å°‘é¢„çƒ­è½®æ•°
        'warmup_momentum': 0.8,
        'box': 7.5,
        'cls': 0.5,
        'dfl': 1.5,
        'hsv_h': 0.015,
        'hsv_s': 0.7,
        'hsv_v': 0.4,
        'degrees': 0.0,
        'translate': 0.1,
        'scale': 0.5,
        'shear': 0.0,
        'perspective': 0.0,
        'flipud': 0.0,
        'fliplr': 0.5,
        'mosaic': 0.3,           # å‡å°‘mosaicæ¦‚ç‡
        'mixup': 0.0,
        'amp': True,             # æ··åˆç²¾åº¦åŠ é€Ÿ
        'cache': False,
        'project': 'runs/test_train',  # åˆ†ç¦»çš„é¡¹ç›®ç›®å½•
        'name': 'exp'            # å®éªŒåç§°
    }

    print("ğŸš€ å¼€å§‹å¿«é€Ÿè®­ç»ƒæ¨¡å‹...")
    print(f"ğŸ“Š è®­ç»ƒè½®æ•°: {epochs}")
    print(f"ğŸ“ å›¾åƒå°ºå¯¸: {img_size}")
    print(f"ğŸ”§ è®¾å¤‡: {device}")

    # å¼€å§‹è®­ç»ƒ
    results = model.train(**training_config)

    print("âœ… å¿«é€Ÿè®­ç»ƒå®Œæˆ!")
    if results and hasattr(results, 'save_dir'):
        print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: {Path(results.save_dir).resolve()}")
    else:
        print("ğŸ“ æ¨¡å‹è®­ç»ƒå®Œæˆ")

    return model, results


def validate_model(model, data_yaml_path: str):
    """éªŒè¯æ¨¡å‹æ€§èƒ½"""
    print("ğŸ” éªŒè¯æ¨¡å‹æ€§èƒ½...")

    # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
    metrics = model.val(data=data_yaml_path)

    print("ğŸ“Š éªŒè¯ç»“æœ:")
    print(f"   mAP@0.5: {metrics.box.map50:.3f}")
    print(f"   mAP@0.5:0.95: {metrics.box.map:.3f}")
    print(f"   ç²¾ç¡®ç‡: {metrics.box.p:.3f}")
    print(f"   å¬å›ç‡: {metrics.box.r:.3f}")

    return metrics


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='é“è·¯ç—…å®³æ£€æµ‹æ¨¡å‹å¿«é€Ÿè®­ç»ƒæµ‹è¯•')
    parser.add_argument('--data', type=str, default='datasets/yolo_format/road.yaml',
                       help='åŸå§‹æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--subset-ratio', type=float, default=0.05,
                       help='å­é›†å åŸå§‹æ•°æ®çš„æ¯”ä¾‹ (é»˜è®¤: 0.05)')
    parser.add_argument('--epochs', type=int, default=10,
                       help='è®­ç»ƒè½®æ•° (é»˜è®¤: 10)')
    parser.add_argument('--img-size', type=int, default=640,
                       help='è¾“å…¥å›¾åƒå°ºå¯¸ (é»˜è®¤: 640)')

    args = parser.parse_args()

    print("ğŸ›£ï¸  é“è·¯ç—…å®³æ£€æµ‹æ¨¡å‹å¿«é€Ÿè®­ç»ƒæµ‹è¯•")
    print("=" * 50)
    print(f"ğŸ“Š é…ç½®: è½®æ•°={args.epochs}, å°ºå¯¸={args.img_size}, å­é›†æ¯”ä¾‹={args.subset_ratio}")

    try:
        # åˆ›å»ºå°è§„æ¨¡æ•°æ®é›†
        subset_yaml_path = create_subset_dataset(
            original_data_yaml=args.data,
            subset_ratio=args.subset_ratio
        )

        # å¿«é€Ÿè®­ç»ƒæ¨¡å‹
        model, training_results = train_model_fast(
            data_yaml_path=subset_yaml_path,
            epochs=args.epochs,
            img_size=args.img_size
        )

        # éªŒè¯æ¨¡å‹
        metrics = validate_model(model, subset_yaml_path)

        print("\nğŸ‰ å¿«é€Ÿè®­ç»ƒæµ‹è¯•å®Œæˆ!")
        print(f"ğŸ“ æµ‹è¯•æ•°æ®é›†: {subset_yaml_path}")
        print(f"ğŸ“Š æœ€ä½³mAP@0.5: {metrics.box.map50:.3f}")

    except Exception as e:
        print(f"âŒ è®­ç»ƒæµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        raise


if __name__ == "__main__":
    main()